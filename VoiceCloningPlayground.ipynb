{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OpeyemiOsakuade/Project-repos/blob/main/VoiceCloningPlayground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QxBxAwp7VXJ",
        "outputId": "81672b53-2f3a-4498-d929-1bcae87274e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFXaVdVurg4j"
      },
      "outputs": [],
      "source": [
        "# cp -a \"/content/drive/MyDrive/Voice Cloning\" \"/content/drive/MyDrive/Text-toSpeech\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txm3qnW10C9g",
        "outputId": "a4149150-575d-43dd-e4bd-425970d678f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/drive/MyDrive/Text-toSpeech/Voice Cloning\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcqzLdDVJnhf",
        "outputId": "2facf6b9-1565-43cc-e7c5-b00fb8f48655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/MyDrive/Text-toSpeech/Voice Cloning/Real-Time-Voice-Cloning'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkeqr3oBx1Kv",
        "outputId": "b28a49c4-5562-4744-a038-7f24706f7d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 7.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting webrtcvad\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 3.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp37-cp37m-linux_x86_64.whl size=72309 sha256=d585326d3a3fe6a938abb0615e9223e88833fc62574bc24d99ae46debb34a4af\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/f9/67/a3158d131f57e1c0a7d8d966a707d4a2fb27567a4fe47723ad\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode\n",
        "!pip install webrtcvad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iJP4hditnba"
      },
      "source": [
        "##Merge Audio---ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5p07oTs1Too",
        "outputId": "63da33e0-faa6-4a3a-a0c1-222890b79037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFVLED1QzlbP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "path = \"/content/drive/MyDrive/Voice Cloning/C Files (File responses)\"\n",
        "out_path = \"/content/drive/MyDrive/Voice Cloning/Female_test\"\n",
        "\n",
        "#Change working directory\n",
        "os.chdir(path)\n",
        "\n",
        "audio_files = os.listdir()\n",
        "for file in audio_files:\n",
        "    #spliting the file into the name and the extension\n",
        "    name, ext = os.path.splitext(file)\n",
        "    if ext == \".mp3\":\n",
        "       mp3_sound = AudioSegment.from_mp3(file)\n",
        "       #rename them using the old name + \".wav\"\n",
        "       mp3_sound.export(out_path +\"/\"+\"{0}.wav\".format(name), format=\"wav\")\n",
        "\n",
        "\n",
        "\n",
        "    #    def make_wav(wrong_folder_path, right_folder_path):           \n",
        "    # for file in os.scandir(wrong_folder_path):                 \n",
        "    #     if (ext == \".mp3\" or ext == \".m4a\" or ext == \".aac\" or ext == \".opus\" or ext == \".ogg\" or ext == \".wma\"):         \n",
        "    #         out_file=right_folder_path+'/'+os.path.splitext(os.path.basename(file.path))[0]+\".wav\"      \n",
        "    #     AudioSegment.from_file(file.path).export(out_file, format=\"wav\")   \n",
        "    #     print(f\"{out_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUjR4FpKfcQ-"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "sound1 = AudioSegment.from_wav(\"filename01.wav\")\n",
        "sound2 = AudioSegment.from_wav(\"filename02.wav\")\n",
        "sound3 = AudioSegment.from_wav(\"filename03.wav\")\n",
        "combined_sounds = sound1 + sound2 + sound3 \n",
        "combined_sounds.export(\"joinedFile.wav\", format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "3FDqscA3gxLj",
        "outputId": "8adf8457-3638-40aa-846f-2efd1aa5b76a"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-fc809d53a383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwavset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Voice Cloning/Female_test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwavs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwavset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# combined = wavs[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fc809d53a383>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwavset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Voice Cloning/Female_test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwavs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwavset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# combined = wavs[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "wavset = \"/content/drive/MyDrive/Voice Cloning/Female_test\"\n",
        "wavs = [AudioSegment.from_wav(wav['path']) for wav in wavset]\n",
        "# combined = wavs[0]\n",
        "\n",
        "# for wav in wavs[1:]:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUzRKNr2_8xK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aJ6gS0n_2uL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okQp8Ftb6e4m",
        "outputId": "ed07cbd4-c7e9-4862-f5d1-48fc386551d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='joinedFile.wav'>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydub import AudioSegment\n",
        "sound1 = AudioSegment.from_wav(\"/content/drive/MyDrive/Voice Cloning/Female_test/Animation Script 1 Chapter 1 - DSN MCF.wav\")\n",
        "sound2 = AudioSegment.from_wav(\"/content/drive/MyDrive/Voice Cloning/Female_test/Animation Script 1 Chapter 2 - DSN MCF.wav\")\n",
        "sound3 = AudioSegment.from_wav(\"/content/drive/MyDrive/Voice Cloning/Female_test/Animation Script 2 Chapter 2 - DSN MCF.wav\")\n",
        "combined_sounds = sound1 + sound2 + sound3 \n",
        "combined_sounds.export(\"joinedFile.wav\", format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIRrUA4GMwF2",
        "outputId": "62ddc3fa-10bd-4a73-9ee4-a39d4b8983a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "pwd: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6qx3BrW7Kj5",
        "outputId": "d694390b-cd84-4806-cf71-61ee297897af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Specific Words (Chapter 1) - DSN MCF (1).wav',\n",
              " 'Animation Script 1 Chapter 1 - DSN MCF.wav',\n",
              " 'Animation Script 2 Chapter 1 - DSN MCF.wav',\n",
              " 'Animation Script 1 Chapter 2 - DSN MCF.wav',\n",
              " 'Animation Script 2 Chapter 2 - DSN MCF.wav',\n",
              " 'Animation Script 3 Chapter 2 - DSN MCF.wav',\n",
              " 'ULearn Script Audio Chapter 2 (12-21) - DSN MCF.wav',\n",
              " 'Ch1Aud1 - DSN MCF.wav',\n",
              " 'Ch1Aud2 - DSN MCF.wav',\n",
              " 'Ch1Aud3 - DSN MCF.wav',\n",
              " 'Ch1Aud4 - DSN MCF.wav',\n",
              " 'Ch1Aud5 - DSN MCF.wav',\n",
              " 'Ch1Aud6 - DSN MCF.wav',\n",
              " 'Specific Words (Chapter 1) - DSN MCF.wav',\n",
              " 'Script_Animation1 Chapter 1 - DSN MCF.wav',\n",
              " 'Script_Animation2 Chapter 1 - DSN MCF.wav',\n",
              " 'Script_Animation1 Chapter 2 - DSN MCF.wav',\n",
              " 'Script_Animation2 Chapter 2 - DSN MCF.wav',\n",
              " 'Script_Animation3 Chapter 2 - DSN MCF.wav',\n",
              " 'ULearn Script_Audio Chapter 2 - DSN MCF.wav',\n",
              " 'Specific Words Chapter 2 - DSN MCF.wav',\n",
              " 'Script_Animation1 Chpt3 - DSN MCF.wav',\n",
              " 'Script_Animation2 Chpt3 - DSN MCF.wav',\n",
              " 'Specific Words Chapter 3 - DSN MCF.wav',\n",
              " 'ULearn Script_AudioCh 3 - DSN MCF.wav',\n",
              " 'Script_Animation 1 Chpt4 - DSN MCF.wav',\n",
              " 'Script_Animation2 Chpt4 - DSN MCF.wav',\n",
              " 'ULearn Script_AudioCh4 - DSN MCF.wav',\n",
              " 'Script_Animation1 Chpt5 - DSN MCF.wav',\n",
              " 'ULearn Script_AudioCh5 - DSN MCF.wav',\n",
              " 'Script_Animation1 Chpt6 - DSN MCF.wav',\n",
              " 'Script_Animation2 Chpt6 - DSN MCF.wav',\n",
              " 'ULearn Script_AudioCh6 - DSN MCF.wav',\n",
              " 'Specific Words Chapter 4 - DSN MCF.wav',\n",
              " 'Specific Words Chapter 5 - DSN MCF.wav',\n",
              " 'Specific Words Chapter 6 - DSN MCF.wav',\n",
              " 'Script_Animation1 Chpt7 - DSN MCF.wav',\n",
              " 'Script_Animation2 Chpt7 - DSN MCF.wav',\n",
              " 'Script_Animation3 Chpt7 - DSN MCF.wav',\n",
              " 'Specific Words Chapter 7 - DSN MCF.wav',\n",
              " 'Script_Animation 1 Chpt8 - DSN MCF.wav',\n",
              " 'Specific Words Chapter 8 - DSN MCF.wav',\n",
              " 'Ch4Aud1_Voice 2 - DSN MCF.wav',\n",
              " 'Ch4Aud2_Voice 2 - DSN MCF.wav',\n",
              " 'Ch4Aud3_Voice 2 - DSN MCF.wav',\n",
              " 'Ch4Aud4_Voice 2 - DSN MCF.wav',\n",
              " 'Ch6Aud1_Voice 2 - DSN MCF.wav',\n",
              " 'Ch6Aud3_Voice 2 - DSN MCF.wav',\n",
              " 'Ch6Aud4_Voice 2 - DSN MCF.wav',\n",
              " 'Ch7Aud1_Voice 2 - DSN MCF.wav',\n",
              " 'Ch7Aud3_Voice 2 - DSN MCF.wav',\n",
              " 'Ch7Aud4_Voice 2 - DSN MCF.wav',\n",
              " 'Ch7Aud5_Voice 2 - DSN MCF.wav',\n",
              " 'Ch7Aud8_Voice 2 - DSN MCF.wav',\n",
              " 'Ch7Aud11_Voice 2 - DSN MCF.wav',\n",
              " 'Ch7Audio13_Voice 2 - DSN MCF.wav',\n",
              " 'Ch8Aud1_Voice 2 - DSN MCF.wav',\n",
              " 'Ch8Aud2_Voice 2 - DSN MCF.wav',\n",
              " 'Ch8Aud3_Voice 2 - DSN MCF.wav',\n",
              " 'Ch8Aud4_Voice 2 - DSN MCF.wav',\n",
              " 'Ch8Aud5_Voice 2 - DSN MCF.wav',\n",
              " 'Ch8Aud6_Voice 2 - DSN MCF.wav',\n",
              " 'Ch8Aud7_Voice 2 - DSN MCF.wav',\n",
              " 'Ch8Aud8_Voice 2 - DSN MCF.wav',\n",
              " 'Ch8Aud10_Voice 2{No 10} - DSN MCF.wav',\n",
              " 'Ch8Aud11_Voice 2 - DSN MCF.wav']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/Voice Cloning/Female_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfuSjwTS8rw8"
      },
      "outputs": [],
      "source": [
        "audio_files = os.listdir()\n",
        "for file in audio_files:\n",
        "    #spliting the file into the name and the extension\n",
        "    name, ext = os.path.splitext(file)\n",
        "    if ext == \".mp3\":\n",
        "       mp3_sound = AudioSegment.from_mp3(file)\n",
        "       #rename them using the old name + \".wav\"\n",
        "       mp3_sound.export(out_path +\"/\"+\"{0}.wav\".format(name), format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-esLUrUs-Myo"
      },
      "outputs": [],
      "source": [
        "wavs = [AudioSegment.from_wav(wav['path']) for wav in wavset]\n",
        "combined = wavs[0]\n",
        "\n",
        "for wav in wavs[1:]:\n",
        "    combined = combined.append(wav)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcG03OWfLAZb",
        "outputId": "c1a36924-7946-4230-df99-4cff95444af7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b0a592590>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b0a592e10>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b0a592e10>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5710>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5710>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5710>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5310>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5710>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5310>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5710>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc55d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5310>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5710>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5290>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc55d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5710>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cf0910>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cf0650>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cf0a50>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cf0910>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b0a592c90>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b0a960550>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b0a592890>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cf0650>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b0a960550>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cf0a50>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cf0910>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5310>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cf0910>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc50d0>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b08969690>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cf0910>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5290>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cf0650>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5290>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cd7410>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5290>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cd7410>\n",
            "<pydub.audio_segment.AudioSegment object at 0x7f9b05cc5290>\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "out_path = os.listdir(\"/content/drive/MyDrive/Voice Cloning/Female_test/\")\n",
        "for audio in out_path:\n",
        "  wav = AudioSegment.from_wav(\"/content/drive/MyDrive/Voice Cloning/Female_test/\"+audio)\n",
        "  print(wav)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwT_2U8v5tc4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "out_path = os.listdir(\"/content/drive/MyDrive/Voice Cloning/Female_test/\")\n",
        "wavs = [AudioSegment.from_wav(\"/content/drive/MyDrive/Voice Cloning/Female_test/\"+audio) for audio in out_path]\n",
        "combined = wavs[0]\n",
        "for wav in wavs[1:]:\n",
        "  combined = combined.append(wav)\n",
        "  combined.export(\"AllFiles.wav\", format=\"wav\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd6l_G1T_2B3"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "sound1 = AudioSegment.from_wav(\"/content/drive/MyDrive/Voice Cloning/Female_test/Specific Words (Chapter 1) - DSN MCF (1).wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn_q6xWU760r"
      },
      "outputs": [],
      "source": [
        "out_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "IcY8n-SZv1AC",
        "outputId": "b43ea087-48f3-4360-90b5-62ec4fbaa4dd"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-272ba0746253>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    mp3_sound.export(out_path +\"/\"+\"{0}.wav\".format(name), format=\"wav\u001b[0m\n\u001b[0m                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
          ]
        }
      ],
      "source": [
        "path = \"/content/drive/MyDrive/Voice Cloning/C Files (File responses)\"\n",
        "out_path = \"/content/drive/MyDrive/Voice Cloning/Female_test\"\n",
        "\n",
        "#Change working directory\n",
        "os.chdir(path)\n",
        "\n",
        "audio_files = os.listdir()\n",
        "for file in audio_files:\n",
        "    #spliting the file into the name and the extension\n",
        "    name, ext = os.path.splitext(file)\n",
        "    if ext == \".mp3\":\n",
        "       mp3_sound = AudioSegment.from_mp3(file)\n",
        "       #rename them using the old name + \".wav\"\n",
        "       mp3_sound.export(out_path +\"/\"+\"{0}.wav\".format(name), format=\"wav\n",
        "\n",
        "os.chdir(out_path)\n",
        "def concatenate_wav(wav_path, orders, wavs):\n",
        "  wavs = [AudioSegment.from_wav(wav['path']) for file in os.listdir()]\n",
        "  combined = wavs[0]\n",
        "  for wav in wavs[1:]:\n",
        "    combined = combined.append(wav)                                                 \n",
        "    combined_wav = None                                                                             \n",
        "    for order, wav in zip(orders, wavs):                                                            \n",
        "        order = AudioSegment.from_wav(wav)                                                          \n",
        "        combined_wav += order                                                                       \n",
        "    combined_wav.export(os.path.join(os.path.dirname(__file__), \"output.wav\"), format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhSgkL57LE67"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "wavs = [AudioSegment.from_wav(wav['path']) for wav in wavset]\n",
        "combined = wavs[0]\n",
        "\n",
        "for wav in wavs[1:]:\n",
        "    combined = combined.append(wav)\n",
        "\n",
        "wav_names = ['wav_0', 'wav_1', 'wav_2'] # more than 3 files...\n",
        "wav_paths:  ['/home/Desktop/tmpowtse1k6.wav', '/home/Desktop/tmpcnm7rljh.\n",
        "wav', '/home/Desktop/tmpyofbtrvk.wav']\n",
        "\n",
        "def _concatenate_wav(orders, wavs):                                                  \n",
        "    combined_wav = None                                                                             \n",
        "    for order, wav in zip(orders, wavs):                                                            \n",
        "        order = AudioSegment.from_wav(wav)                                                          \n",
        "        combined_wav += order                                                                       \n",
        "    combined_wav.export(os.path.join(os.path.dirname(__file__), \"output.wav\"), format=\"wav\")     \n",
        "\n",
        "if __name__ == \"__main__\"\n",
        "    _concatenate_wav(wav_names, wav_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFSFiUfG6gf2",
        "outputId": "1dc1ae57-086b-4cbd-d7d5-d0593dc87b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 36.9 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 44.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 42.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 12.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n",
            "Collecting webrtcvad\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp37-cp37m-linux_x86_64.whl size=72296 sha256=795331166250e4e91b20aa3ab575546b0085d9478b4d8ec05139ea869889d4f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/f9/67/a3158d131f57e1c0a7d8d966a707d4a2fb27567a4fe47723ad\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXe-moa_ZNb2"
      },
      "source": [
        "## Train Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyRzbO8Cw6BP",
        "outputId": "82f8ad27-2d56-4c9e-ae62-939936d6044d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    datasets_root:   /content/drive/MyDrive/Voice Cloning/Text-toSpeech/EduSpeech\n",
            "    out_dir:         /content/drive/MyDrive/Voice Cloning/Text-toSpeech/EduSpeech/SV2TTS/encoder\n",
            "    datasets:        ['eduspeech_clean', 'ng_female', 'ng_male']\n",
            "    skip_existing:   False\n",
            "\n",
            "Preprocessing eduspeech_clean\n",
            "clean-40: Preprocessing data for 17 speakers.\n",
            "clean-40: 100% 17/17 [17:01<00:00, 60.06s/speakers]\n",
            "Done preprocessing clean-40.\n",
            "\n",
            "Preprocessing ng_female\n",
            "en_ng_female: Preprocessing data for 18 speakers.\n",
            "en_ng_female: 100% 18/18 [08:53<00:00, 29.66s/speakers]\n",
            "Done preprocessing en_ng_female.\n",
            "\n",
            "Preprocessing ng_male\n",
            "en_ng_male: Preprocessing data for 12 speakers.\n",
            "en_ng_male: 100% 12/12 [05:39<00:00, 28.28s/speakers]\n",
            "Done preprocessing en_ng_male.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python encoder_preprocess.py \"/content/drive/MyDrive/Voice Cloning/Text-toSpeech/EduSpeech\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "YXXq_slgkhaC",
        "outputId": "8d51fd76-275f-41dc-e5fb-04f73022aacf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWiwR3pvnleY",
        "outputId": "043e57e7-a08d-4c5d-e77f-52c655741ec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting visdom\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 39.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 389 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 419 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 450 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 471 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 481 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 501 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 512 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 532 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 563 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 583 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 624 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 645 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 665 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 676 kB 15.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from visdom) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom) (22.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from visdom) (7.1.2)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (3.0.4)\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=72292b9878844142d683dcd6e0e2d4ec238bdfd690beeb2394e50bbbf64d3cba\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5710 sha256=08208443b3821b11aa89bf03c3eaca44ecefd3024e0da5e69e1dbd16d19e6778\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: jsonpointer, websocket-client, torchfile, jsonpatch, visdom\n",
            "Successfully installed jsonpatch-1.32 jsonpointer-2.2 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install visdom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFmiciOpntxe",
        "outputId": "465b3579-60c2-41f5-990e-de1e8993f5a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting umap-learn==0.3.10\n",
            "  Downloading umap-learn-0.3.10.tar.gz (40 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 30 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from umap-learn==0.3.10) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.7/dist-packages (from umap-learn==0.3.10) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from umap-learn==0.3.10) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.37 in /usr/local/lib/python3.7/dist-packages (from umap-learn==0.3.10) (0.51.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.37->umap-learn==0.3.10) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.37->umap-learn==0.3.10) (0.34.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->umap-learn==0.3.10) (1.1.0)\n",
            "Building wheels for collected packages: umap-learn\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.3.10-py3-none-any.whl size=38883 sha256=721c386148b46f5ac1df8da4365db61267ecf67e0ee27b0f540e280aaf1402f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/d0/8f/9e64bfc5ed0645f89b639196bef92daf5c704285133efce12f\n",
            "Successfully built umap-learn\n",
            "Installing collected packages: umap-learn\n",
            "Successfully installed umap-learn-0.3.10\n"
          ]
        }
      ],
      "source": [
        "!pip install 'umap-learn==0.3.10'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiH36Y1ks_h3"
      },
      "outputs": [],
      "source": [
        "# !wget https://www.openslr.org/resources/12/train-other-500.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8RTUOxduc7o"
      },
      "outputs": [],
      "source": [
        "# !tar -xf /content/train-other-500.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Xu7XGNTlAli7",
        "outputId": "843a3e9a-5883-436a-b70f-dcd59a720f8a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRQ9uRiA5_oI"
      },
      "outputs": [],
      "source": [
        "#pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf19ckhkjI_4",
        "outputId": "516fc038-052f-4ffe-9cc1-6bfbf69c662d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    run_id:            pretrained\n",
            "    clean_data_root:   /content/drive/MyDrive/Voice Cloning/Text-toSpeech/EduSpeech/SV2TTS/encoder\n",
            "    models_dir:        encoder/saved_models\n",
            "    vis_every:         10\n",
            "    umap_every:        10\n",
            "    save_every:        500\n",
            "    backup_every:      10\n",
            "    force_restart:     False\n",
            "    visdom_server:     http://localhost\n",
            "    no_visdom:         True\n",
            "\n",
            "Found existing model \"pretrained\", loading it and resuming training.\n",
            "Updating the visualizations every 10 steps.\n",
            "..........\n",
            "Step 1684510   Loss: 0.3815   EER: 0.0087   Step time:  mean:  1573ms  std:  2700ms\n",
            "Drawing and saving projections (step 1684510)\n",
            "/usr/local/lib/python3.7/dist-packages/umap/spectral.py:229: UserWarning: Embedding a total of 10 separate connected components using meta-embedding (experimental)\n",
            "  n_components\n",
            "Making a backup (step 1684510)\n",
            "\n",
            "Average execution time over 10 steps:\n",
            "  Blocking, waiting for batch (threaded) (10/10):  mean: 1244ms   std: 2686ms\n",
            "  Data to cuda (10/10):                            mean:    3ms   std:    0ms\n",
            "  Forward pass (10/10):                            mean:   46ms   std:    3ms\n",
            "  Loss (10/10):                                    mean:   59ms   std:    7ms\n",
            "  Backward pass (10/10):                           mean:  129ms   std:    7ms\n",
            "  Parameter update (10/10):                        mean:   93ms   std:    3ms\n",
            "  Extras (visualizations, saving) (10/10):         mean:  537ms   std: 1612ms\n",
            "\n",
            "..........\n",
            "Step 1684520   Loss: 0.4287   EER: 0.0099   Step time:  mean:  1105ms  std:  1602ms\n",
            "Drawing and saving projections (step 1684520)\n",
            "/usr/local/lib/python3.7/dist-packages/umap/spectral.py:229: UserWarning: Embedding a total of 10 separate connected components using meta-embedding (experimental)\n",
            "  n_components\n",
            "Making a backup (step 1684520)\n",
            "\n",
            "Average execution time over 10 steps:\n",
            "  Blocking, waiting for batch (threaded) (10/10):  mean:  247ms   std:  467ms\n",
            "  Data to cuda (10/10):                            mean:    3ms   std:    0ms\n",
            "  Forward pass (10/10):                            mean:   44ms   std:    0ms\n",
            "  Loss (10/10):                                    mean:   55ms   std:    6ms\n",
            "  Backward pass (10/10):                           mean:  128ms   std:    9ms\n",
            "  Parameter update (10/10):                        mean:   91ms   std:    3ms\n",
            "  Extras (visualizations, saving) (10/10):         mean:   65ms   std:  195ms\n",
            "\n",
            "..........\n",
            "Step 1684530   Loss: 0.3988   EER: 0.0094   Step time:  mean:   643ms  std:   330ms\n",
            "Drawing and saving projections (step 1684530)\n",
            "/usr/local/lib/python3.7/dist-packages/umap/spectral.py:229: UserWarning: Embedding a total of 10 separate connected components using meta-embedding (experimental)\n",
            "  n_components\n",
            "Making a backup (step 1684530)\n",
            "\n",
            "Average execution time over 10 steps:\n",
            "  Blocking, waiting for batch (threaded) (10/10):  mean:  261ms   std:  321ms\n",
            "  Data to cuda (10/10):                            mean:    3ms   std:    0ms\n",
            "  Forward pass (10/10):                            mean:   44ms   std:    0ms\n",
            "  Loss (10/10):                                    mean:   55ms   std:    5ms\n",
            "  Backward pass (10/10):                           mean:  126ms   std:    7ms\n",
            "  Parameter update (10/10):                        mean:   91ms   std:    2ms\n",
            "  Extras (visualizations, saving) (10/10):         mean:   71ms   std:  212ms\n",
            "\n",
            "..........\n",
            "Step 1684540   Loss: 0.4421   EER: 0.0101   Step time:  mean:   655ms  std:   142ms\n",
            "Drawing and saving projections (step 1684540)\n",
            "/usr/local/lib/python3.7/dist-packages/umap/spectral.py:229: UserWarning: Embedding a total of 10 separate connected components using meta-embedding (experimental)\n",
            "  n_components\n",
            "Making a backup (step 1684540)\n",
            "\n",
            "Average execution time over 10 steps:\n",
            "  Blocking, waiting for batch (threaded) (10/10):  mean:  265ms   std:  111ms\n",
            "  Data to cuda (10/10):                            mean:    3ms   std:    0ms\n",
            "  Forward pass (10/10):                            mean:   44ms   std:    0ms\n",
            "  Loss (10/10):                                    mean:   50ms   std:    4ms\n",
            "  Backward pass (10/10):                           mean:  131ms   std:    9ms\n",
            "  Parameter update (10/10):                        mean:   92ms   std:    2ms\n",
            "  Extras (visualizations, saving) (10/10):         mean:   70ms   std:  210ms\n",
            "\n",
            "..........\n",
            "Step 1684550   Loss: 0.3906   EER: 0.0092   Step time:  mean:   698ms  std:   197ms\n",
            "Drawing and saving projections (step 1684550)\n",
            "/usr/local/lib/python3.7/dist-packages/umap/spectral.py:229: UserWarning: Embedding a total of 10 separate connected components using meta-embedding (experimental)\n",
            "  n_components\n",
            "Making a backup (step 1684550)\n",
            "\n",
            "Average execution time over 10 steps:\n",
            "  Blocking, waiting for batch (threaded) (10/10):  mean:  301ms   std:   69ms\n",
            "  Data to cuda (10/10):                            mean:    3ms   std:    0ms\n",
            "  Forward pass (10/10):                            mean:   44ms   std:    0ms\n",
            "  Loss (10/10):                                    mean:   59ms   std:    5ms\n",
            "  Backward pass (10/10):                           mean:  130ms   std:   12ms\n",
            "  Parameter update (10/10):                        mean:   91ms   std:    1ms\n",
            "  Extras (visualizations, saving) (10/10):         mean:   69ms   std:  206ms\n",
            "\n",
            "..........\n",
            "Step 1684560   Loss: 0.4358   EER: 0.0099   Step time:  mean:   691ms  std:   240ms\n",
            "Drawing and saving projections (step 1684560)\n",
            "/usr/local/lib/python3.7/dist-packages/umap/spectral.py:229: UserWarning: Embedding a total of 10 separate connected components using meta-embedding (experimental)\n",
            "  n_components\n",
            "Making a backup (step 1684560)\n",
            "\n",
            "Average execution time over 10 steps:\n",
            "  Blocking, waiting for batch (threaded) (10/10):  mean:  295ms   std:   70ms\n",
            "  Data to cuda (10/10):                            mean:    3ms   std:    0ms\n",
            "  Forward pass (10/10):                            mean:   44ms   std:    0ms\n",
            "  Loss (10/10):                                    mean:   56ms   std:    5ms\n",
            "  Backward pass (10/10):                           mean:  134ms   std:    7ms\n",
            "  Parameter update (10/10):                        mean:   91ms   std:    3ms\n",
            "  Extras (visualizations, saving) (10/10):         mean:   70ms   std:  208ms\n",
            "\n",
            "..........\n",
            "Step 1684570   Loss: 0.3924   EER: 0.0091   Step time:  mean:   889ms  std:   297ms\n",
            "Drawing and saving projections (step 1684570)\n",
            "/usr/local/lib/python3.7/dist-packages/umap/spectral.py:229: UserWarning: Embedding a total of 10 separate connected components using meta-embedding (experimental)\n",
            "  n_components\n",
            "Making a backup (step 1684570)\n",
            "\n",
            "Average execution time over 10 steps:\n",
            "  Blocking, waiting for batch (threaded) (10/10):  mean:  494ms   std:  279ms\n",
            "  Data to cuda (10/10):                            mean:    3ms   std:    0ms\n",
            "  Forward pass (10/10):                            mean:   44ms   std:    0ms\n",
            "  Loss (10/10):                                    mean:   62ms   std:    9ms\n",
            "  Backward pass (10/10):                           mean:  126ms   std:    9ms\n",
            "  Parameter update (10/10):                        mean:   91ms   std:    2ms\n",
            "  Extras (visualizations, saving) (10/10):         mean:   67ms   std:  202ms\n",
            "\n",
            "..........\n",
            "Step 1684580   Loss: 0.4459   EER: 0.0102   Step time:  mean:   766ms  std:   279ms\n",
            "Drawing and saving projections (step 1684580)\n",
            "/usr/local/lib/python3.7/dist-packages/umap/spectral.py:229: UserWarning: Embedding a total of 10 separate connected components using meta-embedding (experimental)\n",
            "  n_components\n",
            "Making a backup (step 1684580)\n",
            "\n",
            "Average execution time over 10 steps:\n",
            "  Blocking, waiting for batch (threaded) (10/10):  mean:  376ms   std:  238ms\n",
            "  Data to cuda (10/10):                            mean:    3ms   std:    0ms\n",
            "  Forward pass (10/10):                            mean:   44ms   std:    0ms\n",
            "  Loss (10/10):                                    mean:   58ms   std:    5ms\n",
            "  Backward pass (10/10):                           mean:  127ms   std:   10ms\n",
            "  Parameter update (10/10):                        mean:   92ms   std:    3ms\n",
            "  Extras (visualizations, saving) (10/10):         mean:   66ms   std:  199ms\n",
            "\n",
            "..........\n",
            "Step 1684590   Loss: 0.3844   EER: 0.0088   Step time:  mean:   831ms  std:   321ms\n",
            "Drawing and saving projections (step 1684590)\n",
            "/usr/local/lib/python3.7/dist-packages/umap/spectral.py:229: UserWarning: Embedding a total of 9 separate connected components using meta-embedding (experimental)\n",
            "  n_components\n",
            "Making a backup (step 1684590)\n",
            "\n",
            "Average execution time over 10 steps:\n",
            "  Blocking, waiting for batch (threaded) (10/10):  mean:  439ms   std:  299ms\n",
            "  Data to cuda (10/10):                            mean:    3ms   std:    0ms\n",
            "  Forward pass (10/10):                            mean:   44ms   std:    0ms\n",
            "  Loss (10/10):                                    mean:   59ms   std:    8ms\n",
            "  Backward pass (10/10):                           mean:  130ms   std:    9ms\n",
            "  Parameter update (10/10):                        mean:   90ms   std:    2ms\n",
            "  Extras (visualizations, saving) (10/10):         mean:   68ms   std:  204ms\n",
            "\n",
            "..........\n",
            "Step 1684600   Loss: 0.4126   EER: 0.0095   Step time:  mean:   745ms  std:   231ms\n",
            "Drawing and saving projections (step 1684600)\n",
            "/usr/local/lib/python3.7/dist-packages/umap/spectral.py:229: UserWarning: Embedding a total of 10 separate connected components using meta-embedding (experimental)\n",
            "  n_components\n",
            "Making a backup (step 1684600)\n",
            "\n",
            "Average execution time over 10 steps:\n",
            "  Blocking, waiting for batch (threaded) (10/10):  mean:  362ms   std:  164ms\n",
            "  Data to cuda (10/10):                            mean:    2ms   std:    0ms\n",
            "  Forward pass (10/10):                            mean:   44ms   std:    0ms\n",
            "  Loss (10/10):                                    mean:   53ms   std:    4ms\n",
            "  Backward pass (10/10):                           mean:  125ms   std:   10ms\n",
            "  Parameter update (10/10):                        mean:   91ms   std:    2ms\n",
            "  Extras (visualizations, saving) (10/10):         mean:   68ms   std:  203ms\n",
            "\n",
            "..........\n",
            "Step 1684610   Loss: 0.4090   EER: 0.0094   Step time:  mean:   872ms  std:   286ms\n",
            "Drawing and saving projections (step 1684610)\n",
            "/usr/local/lib/python3.7/dist-packages/umap/spectral.py:229: UserWarning: Embedding a total of 10 separate connected components using meta-embedding (experimental)\n",
            "  n_components\n",
            "Making a backup (step 1684610)\n",
            "\n",
            "Average execution time over 10 steps:\n",
            "  Blocking, waiting for batch (threaded) (10/10):  mean:  487ms   std:  251ms\n",
            "  Data to cuda (10/10):                            mean:    3ms   std:    0ms\n",
            "  Forward pass (10/10):                            mean:   44ms   std:    0ms\n",
            "  Loss (10/10):                                    mean:   53ms   std:    5ms\n",
            "  Backward pass (10/10):                           mean:  125ms   std:   11ms\n",
            "  Parameter update (10/10):                        mean:   92ms   std:    2ms\n",
            "  Extras (visualizations, saving) (10/10):         mean:   68ms   std:  204ms\n",
            "\n",
            ".......Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1186, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1152, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 990, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"encoder_train.py\", line 46, in <module>\n",
            "    train(**vars(args))\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/encoder/train.py\", line 67, in train\n",
            "    for step, speaker_batch in enumerate(loader, init_step):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python encoder_train.py pretrained \"/content/drive/MyDrive/Voice Cloning/Text-toSpeech/EduSpeech/SV2TTS/encoder\" --no_visdom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtzgMkn8EfVQ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "create alignment file before all this below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XolY5SkEkLRU"
      },
      "outputs": [],
      "source": [
        "# path = '/content/drive/MyDrive/Voice Cloning/Text-toSpeech/sample_aligned'\n",
        "# TextGrid_file = os.listdir(path)\n",
        "\n",
        "# # \n",
        "# with open('/content/drive/MyDrive/Voice Cloning/Text-toSpeech/ljs/sample/wavs/DrBayo300-499.alignment.txt','a') as the_file:\n",
        "#   for tg in TextGrid_file:\n",
        "#     copying = 0\n",
        "#     word_dict = {'xmin' :[], 'xmax':[],'text':[]}\n",
        "#     with open(f'{path}/{tg}', 'r') as f:\n",
        "#       for line in f:\n",
        "#         if 'item [1]' in line:\n",
        "#           copying = 1\n",
        "#         if 'item [2]' in line:\n",
        "#           break\n",
        "#         if copying == 1:\n",
        "#           if 'xmin' in line:\n",
        "#             word_dict['xmin'].append(line.split('=')[1].split('\\n')[0].split(' ')[1])\n",
        "#           if 'xmax' in line:\n",
        "#             word_dict['xmax'].append(line.split('=')[1].split('\\n')[0].split(' ')[1])\n",
        "#           if 'text' in line:\n",
        "#             word_dict['text'].append(line.split('=')[1].split('\"')[1].upper())\n",
        "    \n",
        "#     #lenght check\n",
        "#     assert len(word_dict['text']) == len(word_dict['xmax'][1:])\n",
        "\n",
        "#     timestamp = ''\n",
        "#     for t in word_dict['xmax'][1:]:\n",
        "#       timestamp = f\"{timestamp}{t},\"\n",
        "\n",
        "#     word_cut = ''\n",
        "#     for w in word_dict['text']:\n",
        "#       word_cut = f\"{word_cut}{w},\"\n",
        "      \n",
        "#     audio_name = tg.split('.')[0]\n",
        "\n",
        "#     # print(len(word_cut[:-1].split(',')), len(timestamp[:-1].split(',')))\n",
        "#     assert len(word_cut[:-1].split(',')) == len(timestamp[:-1].split(','))\n",
        "    \n",
        "#     gen_line = f'{audio_name} \"{word_cut[:-1]}\" \"{timestamp[:-1]}\"\\n'\n",
        "#     # print(gen_line)\n",
        "#     the_file.write(gen_line)\n",
        "#     # break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX7QZUQUyPt6"
      },
      "outputs": [],
      "source": [
        "# !git clone -l -s git://github.com/CorentinJ/Real-Time-Voice-Cloning.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFh112QvOvuW"
      },
      "source": [
        "## Train Synthesizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w94PPev2u6ZQ",
        "outputId": "375a1591-1ef2-48d6-b3e0-41980e60094c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    datasets_root:   /content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root\n",
            "    out_dir:         /content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer\n",
            "    n_processes:     None\n",
            "    skip_existing:   False\n",
            "    hparams:         \n",
            "    no_alignments:   False\n",
            "    datasets_name:   Sample2_female_voice(60mins)\n",
            "    subfolders:      audioNtranscript\n",
            "\n",
            "Using data from:\n",
            "    /content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/Sample2_female_voice(60mins)/audioNtranscript\n",
            "=====Speaker directory========\n",
            "[PosixPath('/content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/Sample2_female_voice(60mins)/audioNtranscript/transcript.txt'), PosixPath('/content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/Sample2_female_voice(60mins)/audioNtranscript/sample')]\n",
            "Sample2_female_voice(60mins): 100% 2/2 [04:31<00:00, 135.89s/speakers]\n",
            "The dataset consists of 868 utterances, 200055 mel frames, 39910080 audio timesteps (0.69 hours).\n",
            "Max input length (text chars): 142\n",
            "Max mel frames length: 752\n",
            "Max audio timesteps length: 150240\n"
          ]
        }
      ],
      "source": [
        "!python synthesizer_preprocess_audio.py '/content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root' --datasets_name 'Sample2_female_voice(60mins)' --subfolders 'audioNtranscript' -o \"/content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Lzfw8oxdJd5",
        "outputId": "e9e4f557-4bf7-497f-b31c-676a40bab761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    synthesizer_root:      /content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer\n",
            "    encoder_model_fpath:   /content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/encoder/saved_models/pretrained_backups/pretrained_bak_1684610.pt\n",
            "    n_processes:           4\n",
            "\n",
            "Embedding:   0% 0/868 [00:00<?, ?utterances/s]Loaded encoder \"pretrained_bak_1684610.pt\" trained to step 1684611\n",
            "Loaded encoder \"pretrained_bak_1684610.pt\" trained to step 1684611\n",
            "Loaded encoder \"pretrained_bak_1684610.pt\" trained to step 1684611\n",
            "Loaded encoder \"pretrained_bak_1684610.pt\" trained to step 1684611\n",
            "Embedding: 100% 868/868 [00:40<00:00, 21.49utterances/s]\n"
          ]
        }
      ],
      "source": [
        "!python synthesizer_preprocess_embeds.py \"/content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer\" -e \"/content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/encoder/saved_models/pretrained_backups/pretrained_bak_1684610.pt\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "X-hrX9VBl3ZI",
        "outputId": "d6eff5a9-1c0f-455f-c0b7-b5cda9e7acb3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27O1TdcRloJ-",
        "outputId": "657be9aa-1998-4dc1-abac-718f28273a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: synthesizer_train.py [-h] [-m MODELS_DIR] [-s SAVE_EVERY]\n",
            "                            [-b BACKUP_EVERY] [-f] [--hparams HPARAMS]\n",
            "                            run_id syn_dir\n",
            "synthesizer_train.py: error: the following arguments are required: run_id, syn_dir\n"
          ]
        }
      ],
      "source": [
        "!python synthesizer_train.py pretrained \"/content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer\" -s 200 -b 1000 #--checkpoint_interval 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL6c-tlM2hR9"
      },
      "outputs": [],
      "source": [
        "#######renamed synthesizer _312 to synthesizer.pt /// To make sure it starts from the last checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHb-7hz8mrsK",
        "outputId": "dfe7afe7-eca4-49ce-f4ad-72d8c053fe84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1938/22858 (14/14) | Loss: 0.1686 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1939/22858 (14/14) | Loss: 0.1688 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1940/22858 (14/14) | Loss: 0.1689 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1941/22858 (14/14) | Loss: 0.1697 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1942/22858 (14/14) | Loss: 0.1687 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1943/22858 (14/14) | Loss: 0.1685 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1944/22858 (14/14) | Loss: 0.1684 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1945/22858 (14/14) | Loss: 0.1684 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1946/22858 (14/14) | Loss: 0.1688 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1947/22858 (14/14) | Loss: 0.1707 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1948/22858 (14/14) | Loss: 0.1703 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1949/22858 (14/14) | Loss: 0.1708 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1950/22858 (14/14) | Loss: 0.1714 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1951/22858 (14/14) | Loss: 0.1726 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1952/22858 (14/14) | Loss: 0.1732 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1953/22858 (14/14) | Loss: 0.1735 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1954/22858 (14/14) | Loss: 0.1724 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1955/22858 (14/14) | Loss: 0.1722 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1956/22858 (14/14) | Loss: 0.1723 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1957/22858 (14/14) | Loss: 0.1717 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1958/22858 (14/14) | Loss: 0.1711 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1959/22858 (14/14) | Loss: 0.1698 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1960/22858 (14/14) | Loss: 0.1689 | 0.59 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1961/22858 (14/14) | Loss: 0.1688 | 0.59 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1962/22858 (14/14) | Loss: 0.1689 | 0.59 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1963/22858 (14/14) | Loss: 0.1692 | 0.59 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1964/22858 (14/14) | Loss: 0.1683 | 0.59 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1965/22858 (4/14) | Loss: 0.1688 | 0.59 steps/s | Step: 347k | }Input at step 347500: the first thing is to do is to get the robot~____________________________________________________________\n",
            "{| Epoch: 1965/22858 (14/14) | Loss: 0.1677 | 0.59 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1966/22858 (14/14) | Loss: 0.1685 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1967/22858 (14/14) | Loss: 0.1688 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1968/22858 (14/14) | Loss: 0.1681 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1969/22858 (14/14) | Loss: 0.1680 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1970/22858 (14/14) | Loss: 0.1674 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1971/22858 (14/14) | Loss: 0.1671 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1972/22858 (14/14) | Loss: 0.1679 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1973/22858 (14/14) | Loss: 0.1674 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1974/22858 (14/14) | Loss: 0.1675 | 0.60 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1975/22858 (14/14) | Loss: 0.1682 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1976/22858 (14/14) | Loss: 0.1694 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1977/22858 (14/14) | Loss: 0.1697 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1978/22858 (14/14) | Loss: 0.1702 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1979/22858 (14/14) | Loss: 0.1715 | 0.62 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1980/22858 (14/14) | Loss: 0.1719 | 0.62 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1981/22858 (14/14) | Loss: 0.1715 | 0.62 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1982/22858 (14/14) | Loss: 0.1707 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1983/22858 (14/14) | Loss: 0.1704 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1984/22858 (14/14) | Loss: 0.1705 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1985/22858 (14/14) | Loss: 0.1705 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1986/22858 (14/14) | Loss: 0.1707 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1987/22858 (14/14) | Loss: 0.1716 | 0.62 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1988/22858 (14/14) | Loss: 0.1715 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1989/22858 (14/14) | Loss: 0.1720 | 0.62 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1990/22858 (14/14) | Loss: 0.1724 | 0.62 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1991/22858 (14/14) | Loss: 0.1712 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1992/22858 (14/14) | Loss: 0.1708 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1993/22858 (14/14) | Loss: 0.1702 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1994/22858 (14/14) | Loss: 0.1701 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1995/22858 (14/14) | Loss: 0.1694 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1996/22858 (14/14) | Loss: 0.1689 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1997/22858 (14/14) | Loss: 0.1689 | 0.61 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1998/22858 (14/14) | Loss: 0.1700 | 0.62 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1999/22858 (14/14) | Loss: 0.1700 | 0.62 steps/s | Step: 347k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2000/22858 (14/14) | Loss: 0.1689 | 0.61 steps/s | Step: 348k | }Input at step 348000: speech recognition it's a noun~___________________________________________________________________________\n",
            "\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2001/22858 (14/14) | Loss: 0.1690 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2002/22858 (14/14) | Loss: 0.1688 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2003/22858 (14/14) | Loss: 0.1694 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2004/22858 (14/14) | Loss: 0.1692 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2005/22858 (14/14) | Loss: 0.1700 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2006/22858 (14/14) | Loss: 0.1695 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2007/22858 (14/14) | Loss: 0.1697 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2008/22858 (14/14) | Loss: 0.1697 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2009/22858 (14/14) | Loss: 0.1689 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2010/22858 (14/14) | Loss: 0.1694 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2011/22858 (14/14) | Loss: 0.1685 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2012/22858 (14/14) | Loss: 0.1684 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2013/22858 (14/14) | Loss: 0.1690 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2014/22858 (14/14) | Loss: 0.1683 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2015/22858 (14/14) | Loss: 0.1677 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2016/22858 (14/14) | Loss: 0.1680 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2017/22858 (14/14) | Loss: 0.1683 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2018/22858 (14/14) | Loss: 0.1682 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2019/22858 (14/14) | Loss: 0.1678 | 0.60 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2020/22858 (14/14) | Loss: 0.1681 | 0.60 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2021/22858 (14/14) | Loss: 0.1678 | 0.60 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2022/22858 (14/14) | Loss: 0.1679 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2023/22858 (14/14) | Loss: 0.1679 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2024/22858 (14/14) | Loss: 0.1682 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2025/22858 (14/14) | Loss: 0.1678 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2026/22858 (14/14) | Loss: 0.1684 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2027/22858 (14/14) | Loss: 0.1682 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2028/22858 (14/14) | Loss: 0.1677 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2029/22858 (14/14) | Loss: 0.1685 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2030/22858 (14/14) | Loss: 0.1687 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2031/22858 (14/14) | Loss: 0.1681 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2032/22858 (14/14) | Loss: 0.1692 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2033/22858 (14/14) | Loss: 0.1686 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2034/22858 (14/14) | Loss: 0.1694 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2035/22858 (14/14) | Loss: 0.1699 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2036/22858 (10/14) | Loss: 0.1708 | 0.61 steps/s | Step: 348k | }Input at step 348500: this video i will work you through some of the notable application~_______________________________________\n",
            "{| Epoch: 2036/22858 (14/14) | Loss: 0.1700 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2037/22858 (14/14) | Loss: 0.1696 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2038/22858 (14/14) | Loss: 0.1700 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2039/22858 (14/14) | Loss: 0.1696 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2040/22858 (14/14) | Loss: 0.1707 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2041/22858 (14/14) | Loss: 0.1701 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2042/22858 (14/14) | Loss: 0.1687 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2043/22858 (14/14) | Loss: 0.1689 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2044/22858 (14/14) | Loss: 0.1695 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2045/22858 (14/14) | Loss: 0.1687 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2046/22858 (14/14) | Loss: 0.1684 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2047/22858 (14/14) | Loss: 0.1687 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2048/22858 (14/14) | Loss: 0.1686 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2049/22858 (14/14) | Loss: 0.1692 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2050/22858 (14/14) | Loss: 0.1681 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2051/22858 (14/14) | Loss: 0.1678 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2052/22858 (14/14) | Loss: 0.1672 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2053/22858 (14/14) | Loss: 0.1667 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2054/22858 (14/14) | Loss: 0.1662 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2055/22858 (14/14) | Loss: 0.1664 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2056/22858 (14/14) | Loss: 0.1661 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2057/22858 (14/14) | Loss: 0.1657 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2058/22858 (14/14) | Loss: 0.1656 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2059/22858 (14/14) | Loss: 0.1662 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2060/22858 (14/14) | Loss: 0.1675 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2061/22858 (14/14) | Loss: 0.1677 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2062/22858 (14/14) | Loss: 0.1688 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2063/22858 (14/14) | Loss: 0.1681 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2064/22858 (14/14) | Loss: 0.1685 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2065/22858 (14/14) | Loss: 0.1692 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2066/22858 (14/14) | Loss: 0.1680 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2067/22858 (14/14) | Loss: 0.1678 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2068/22858 (14/14) | Loss: 0.1671 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2069/22858 (14/14) | Loss: 0.1671 | 0.62 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2070/22858 (14/14) | Loss: 0.1673 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2071/22858 (14/14) | Loss: 0.1670 | 0.61 steps/s | Step: 348k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2072/22858 (6/14) | Loss: 0.1671 | 0.61 steps/s | Step: 349k | }Input at step 349000: you are interacting with a i~_________________________________________________________________________________________________________________\n",
            "{| Epoch: 2072/22858 (14/14) | Loss: 0.1672 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2073/22858 (14/14) | Loss: 0.1683 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2074/22858 (14/14) | Loss: 0.1687 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2075/22858 (14/14) | Loss: 0.1688 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2076/22858 (14/14) | Loss: 0.1683 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2077/22858 (14/14) | Loss: 0.1681 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2078/22858 (14/14) | Loss: 0.1693 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2079/22858 (14/14) | Loss: 0.1700 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2080/22858 (14/14) | Loss: 0.1699 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2081/22858 (14/14) | Loss: 0.1705 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2082/22858 (14/14) | Loss: 0.1708 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2083/22858 (14/14) | Loss: 0.1700 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2084/22858 (14/14) | Loss: 0.1706 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2085/22858 (14/14) | Loss: 0.1706 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2086/22858 (14/14) | Loss: 0.1701 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2087/22858 (14/14) | Loss: 0.1696 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2088/22858 (14/14) | Loss: 0.1684 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2089/22858 (14/14) | Loss: 0.1691 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2090/22858 (14/14) | Loss: 0.1680 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2091/22858 (14/14) | Loss: 0.1671 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2092/22858 (14/14) | Loss: 0.1670 | 0.60 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2093/22858 (14/14) | Loss: 0.1671 | 0.60 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2094/22858 (14/14) | Loss: 0.1668 | 0.60 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2095/22858 (14/14) | Loss: 0.1663 | 0.60 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2096/22858 (14/14) | Loss: 0.1658 | 0.60 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2097/22858 (14/14) | Loss: 0.1664 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2098/22858 (14/14) | Loss: 0.1669 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2099/22858 (14/14) | Loss: 0.1664 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2100/22858 (14/14) | Loss: 0.1666 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2101/22858 (14/14) | Loss: 0.1668 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2102/22858 (14/14) | Loss: 0.1667 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2103/22858 (14/14) | Loss: 0.1678 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2104/22858 (14/14) | Loss: 0.1680 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2105/22858 (14/14) | Loss: 0.1662 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2106/22858 (14/14) | Loss: 0.1658 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2107/22858 (14/14) | Loss: 0.1664 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2108/22858 (2/14) | Loss: 0.1668 | 0.61 steps/s | Step: 349k | }Input at step 349500: will need to carry out the same task many times~_______________________________________\n",
            "{| Epoch: 2108/22858 (14/14) | Loss: 0.1661 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2109/22858 (14/14) | Loss: 0.1662 | 0.60 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2110/22858 (14/14) | Loss: 0.1668 | 0.60 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2111/22858 (14/14) | Loss: 0.1667 | 0.60 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2112/22858 (14/14) | Loss: 0.1668 | 0.60 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2113/22858 (14/14) | Loss: 0.1670 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2114/22858 (14/14) | Loss: 0.1673 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2115/22858 (14/14) | Loss: 0.1677 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2116/22858 (14/14) | Loss: 0.1680 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2117/22858 (14/14) | Loss: 0.1675 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2118/22858 (14/14) | Loss: 0.1677 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2119/22858 (14/14) | Loss: 0.1672 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2120/22858 (14/14) | Loss: 0.1683 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2121/22858 (14/14) | Loss: 0.1683 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2122/22858 (14/14) | Loss: 0.1676 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2123/22858 (14/14) | Loss: 0.1683 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2124/22858 (14/14) | Loss: 0.1688 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2125/22858 (14/14) | Loss: 0.1691 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2126/22858 (14/14) | Loss: 0.1695 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2127/22858 (14/14) | Loss: 0.1684 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2128/22858 (14/14) | Loss: 0.1680 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2129/22858 (14/14) | Loss: 0.1693 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2130/22858 (14/14) | Loss: 0.1691 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2131/22858 (14/14) | Loss: 0.1688 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2132/22858 (14/14) | Loss: 0.1678 | 0.63 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2133/22858 (14/14) | Loss: 0.1670 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2134/22858 (14/14) | Loss: 0.1670 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2135/22858 (14/14) | Loss: 0.1675 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2136/22858 (14/14) | Loss: 0.1690 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2137/22858 (14/14) | Loss: 0.1678 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2138/22858 (14/14) | Loss: 0.1684 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2139/22858 (14/14) | Loss: 0.1685 | 0.61 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2140/22858 (14/14) | Loss: 0.1692 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2141/22858 (14/14) | Loss: 0.1688 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2142/22858 (14/14) | Loss: 0.1686 | 0.62 steps/s | Step: 349k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2143/22858 (12/14) | Loss: 0.1670 | 0.61 steps/s | Step: 350k | }Input at step 350000: the model decides that the book is good~______________________________________________________________________________________________________\n",
            "{| Epoch: 2143/22858 (14/14) | Loss: 0.1671 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2144/22858 (14/14) | Loss: 0.1672 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2145/22858 (14/14) | Loss: 0.1676 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2146/22858 (14/14) | Loss: 0.1677 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2147/22858 (14/14) | Loss: 0.1679 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2148/22858 (14/14) | Loss: 0.1671 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2149/22858 (14/14) | Loss: 0.1685 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2150/22858 (14/14) | Loss: 0.1692 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2151/22858 (14/14) | Loss: 0.1693 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2152/22858 (14/14) | Loss: 0.1685 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2153/22858 (14/14) | Loss: 0.1686 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2154/22858 (14/14) | Loss: 0.1679 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2155/22858 (14/14) | Loss: 0.1678 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2156/22858 (14/14) | Loss: 0.1687 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2157/22858 (14/14) | Loss: 0.1663 | 0.59 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2158/22858 (14/14) | Loss: 0.1688 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2159/22858 (14/14) | Loss: 0.1683 | 0.59 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2160/22858 (14/14) | Loss: 0.1677 | 0.59 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2161/22858 (14/14) | Loss: 0.1673 | 0.59 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2162/22858 (14/14) | Loss: 0.1680 | 0.59 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2163/22858 (14/14) | Loss: 0.1668 | 0.58 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2164/22858 (14/14) | Loss: 0.1670 | 0.59 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2165/22858 (14/14) | Loss: 0.1671 | 0.59 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2166/22858 (14/14) | Loss: 0.1668 | 0.59 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2167/22858 (14/14) | Loss: 0.1668 | 0.59 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2168/22858 (14/14) | Loss: 0.1669 | 0.59 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2169/22858 (14/14) | Loss: 0.1680 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2170/22858 (14/14) | Loss: 0.1678 | 0.59 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2171/22858 (14/14) | Loss: 0.1683 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2172/22858 (14/14) | Loss: 0.1681 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2173/22858 (14/14) | Loss: 0.1695 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2174/22858 (14/14) | Loss: 0.1693 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2175/22858 (14/14) | Loss: 0.1688 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2176/22858 (14/14) | Loss: 0.1685 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2177/22858 (14/14) | Loss: 0.1698 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2178/22858 (14/14) | Loss: 0.1699 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2179/22858 (8/14) | Loss: 0.1692 | 0.61 steps/s | Step: 350k | }Input at step 350500: in a sentence emeka stopped to buy some groceries from the mall~______________________________________________________________________________\n",
            "{| Epoch: 2179/22858 (14/14) | Loss: 0.1692 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2180/22858 (14/14) | Loss: 0.1697 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2181/22858 (14/14) | Loss: 0.1691 | 0.62 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2182/22858 (14/14) | Loss: 0.1699 | 0.62 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2183/22858 (14/14) | Loss: 0.1703 | 0.62 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2184/22858 (14/14) | Loss: 0.1698 | 0.62 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2185/22858 (14/14) | Loss: 0.1699 | 0.62 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2186/22858 (14/14) | Loss: 0.1703 | 0.62 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2187/22858 (14/14) | Loss: 0.1694 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2188/22858 (14/14) | Loss: 0.1692 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2189/22858 (14/14) | Loss: 0.1680 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2190/22858 (14/14) | Loss: 0.1681 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2191/22858 (14/14) | Loss: 0.1672 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2192/22858 (14/14) | Loss: 0.1666 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2193/22858 (14/14) | Loss: 0.1671 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2194/22858 (14/14) | Loss: 0.1668 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2195/22858 (14/14) | Loss: 0.1672 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2196/22858 (14/14) | Loss: 0.1672 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2197/22858 (14/14) | Loss: 0.1682 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2198/22858 (14/14) | Loss: 0.1685 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2199/22858 (14/14) | Loss: 0.1693 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2200/22858 (14/14) | Loss: 0.1691 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2201/22858 (14/14) | Loss: 0.1679 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2202/22858 (14/14) | Loss: 0.1675 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2203/22858 (14/14) | Loss: 0.1667 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2204/22858 (14/14) | Loss: 0.1668 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2205/22858 (14/14) | Loss: 0.1671 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2206/22858 (14/14) | Loss: 0.1667 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2207/22858 (14/14) | Loss: 0.1678 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2208/22858 (14/14) | Loss: 0.1677 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2209/22858 (14/14) | Loss: 0.1681 | 0.62 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2210/22858 (14/14) | Loss: 0.1692 | 0.62 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2211/22858 (14/14) | Loss: 0.1694 | 0.62 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2212/22858 (14/14) | Loss: 0.1690 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2213/22858 (14/14) | Loss: 0.1675 | 0.61 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2214/22858 (14/14) | Loss: 0.1667 | 0.60 steps/s | Step: 350k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2215/22858 (4/14) | Loss: 0.1663 | 0.60 steps/s | Step: 351k | }Input at step 351000: we always have to give accurate~______________________________________________________________________________________________________________\n",
            "{| Epoch: 2215/22858 (14/14) | Loss: 0.1665 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2216/22858 (14/14) | Loss: 0.1664 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2217/22858 (14/14) | Loss: 0.1658 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2218/22858 (14/14) | Loss: 0.1662 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2219/22858 (14/14) | Loss: 0.1660 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2220/22858 (14/14) | Loss: 0.1660 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2221/22858 (14/14) | Loss: 0.1668 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2222/22858 (14/14) | Loss: 0.1663 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2223/22858 (14/14) | Loss: 0.1666 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2224/22858 (14/14) | Loss: 0.1665 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2225/22858 (14/14) | Loss: 0.1667 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2226/22858 (14/14) | Loss: 0.1665 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2227/22858 (14/14) | Loss: 0.1674 | 0.62 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2228/22858 (14/14) | Loss: 0.1662 | 0.62 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2229/22858 (14/14) | Loss: 0.1675 | 0.63 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2230/22858 (14/14) | Loss: 0.1676 | 0.62 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2231/22858 (14/14) | Loss: 0.1680 | 0.62 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2232/22858 (14/14) | Loss: 0.1682 | 0.63 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2233/22858 (14/14) | Loss: 0.1682 | 0.62 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2234/22858 (14/14) | Loss: 0.1687 | 0.62 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2235/22858 (14/14) | Loss: 0.1692 | 0.63 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2236/22858 (14/14) | Loss: 0.1691 | 0.63 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2237/22858 (14/14) | Loss: 0.1703 | 0.63 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2238/22858 (14/14) | Loss: 0.1702 | 0.63 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2239/22858 (14/14) | Loss: 0.1693 | 0.63 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2240/22858 (14/14) | Loss: 0.1688 | 0.63 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2241/22858 (14/14) | Loss: 0.1692 | 0.63 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2242/22858 (14/14) | Loss: 0.1676 | 0.62 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2243/22858 (14/14) | Loss: 0.1677 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2244/22858 (14/14) | Loss: 0.1684 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2245/22858 (14/14) | Loss: 0.1671 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2246/22858 (14/14) | Loss: 0.1661 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2247/22858 (14/14) | Loss: 0.1669 | 0.59 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2248/22858 (14/14) | Loss: 0.1669 | 0.59 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2249/22858 (14/14) | Loss: 0.1674 | 0.59 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2250/22858 (14/14) | Loss: 0.1673 | 0.60 steps/s | Step: 351k | }Input at step 351500: what we do is teach the computer by showing it many examples of books~__________________________________\n",
            "\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2251/22858 (14/14) | Loss: 0.1667 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2252/22858 (14/14) | Loss: 0.1670 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2253/22858 (14/14) | Loss: 0.1668 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2254/22858 (14/14) | Loss: 0.1671 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2255/22858 (14/14) | Loss: 0.1655 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2256/22858 (14/14) | Loss: 0.1663 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2257/22858 (14/14) | Loss: 0.1670 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2258/22858 (14/14) | Loss: 0.1674 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2259/22858 (14/14) | Loss: 0.1670 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2260/22858 (14/14) | Loss: 0.1677 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2261/22858 (14/14) | Loss: 0.1685 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2262/22858 (14/14) | Loss: 0.1678 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2263/22858 (14/14) | Loss: 0.1679 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2264/22858 (14/14) | Loss: 0.1679 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2265/22858 (14/14) | Loss: 0.1687 | 0.62 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2266/22858 (14/14) | Loss: 0.1676 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2267/22858 (14/14) | Loss: 0.1686 | 0.61 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2268/22858 (14/14) | Loss: 0.1682 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2269/22858 (14/14) | Loss: 0.1687 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2270/22858 (14/14) | Loss: 0.1685 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2271/22858 (14/14) | Loss: 0.1684 | 0.59 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2272/22858 (14/14) | Loss: 0.1678 | 0.59 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2273/22858 (14/14) | Loss: 0.1681 | 0.59 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2274/22858 (14/14) | Loss: 0.1673 | 0.59 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2275/22858 (14/14) | Loss: 0.1671 | 0.59 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2276/22858 (14/14) | Loss: 0.1671 | 0.59 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2277/22858 (14/14) | Loss: 0.1672 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2278/22858 (14/14) | Loss: 0.1665 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2279/22858 (14/14) | Loss: 0.1676 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2280/22858 (14/14) | Loss: 0.1676 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2281/22858 (14/14) | Loss: 0.1676 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2282/22858 (14/14) | Loss: 0.1677 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2283/22858 (14/14) | Loss: 0.1669 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2284/22858 (14/14) | Loss: 0.1680 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2285/22858 (14/14) | Loss: 0.1681 | 0.60 steps/s | Step: 351k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2286/22858 (10/14) | Loss: 0.1674 | 0.60 steps/s | Step: 352k | }Input at step 352000: it has been used in it for many years~_____________________________________________________________________________________________\n",
            "{| Epoch: 2286/22858 (14/14) | Loss: 0.1679 | 0.60 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2287/22858 (14/14) | Loss: 0.1669 | 0.60 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2288/22858 (14/14) | Loss: 0.1674 | 0.60 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2289/22858 (14/14) | Loss: 0.1682 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2290/22858 (14/14) | Loss: 0.1682 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2291/22858 (14/14) | Loss: 0.1675 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2292/22858 (14/14) | Loss: 0.1673 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2293/22858 (14/14) | Loss: 0.1666 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2294/22858 (14/14) | Loss: 0.1669 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2295/22858 (14/14) | Loss: 0.1665 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2296/22858 (14/14) | Loss: 0.1662 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2297/22858 (14/14) | Loss: 0.1669 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2298/22858 (14/14) | Loss: 0.1673 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2299/22858 (14/14) | Loss: 0.1687 | 0.63 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2300/22858 (14/14) | Loss: 0.1685 | 0.63 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2301/22858 (14/14) | Loss: 0.1688 | 0.63 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2302/22858 (14/14) | Loss: 0.1692 | 0.63 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2303/22858 (14/14) | Loss: 0.1678 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2304/22858 (14/14) | Loss: 0.1688 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2305/22858 (14/14) | Loss: 0.1681 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2306/22858 (14/14) | Loss: 0.1670 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2307/22858 (14/14) | Loss: 0.1666 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2308/22858 (14/14) | Loss: 0.1667 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2309/22858 (14/14) | Loss: 0.1667 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2310/22858 (14/14) | Loss: 0.1676 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2311/22858 (14/14) | Loss: 0.1671 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2312/22858 (14/14) | Loss: 0.1675 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2313/22858 (14/14) | Loss: 0.1678 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2314/22858 (14/14) | Loss: 0.1677 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2315/22858 (14/14) | Loss: 0.1681 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2316/22858 (14/14) | Loss: 0.1687 | 0.63 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2317/22858 (14/14) | Loss: 0.1690 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2318/22858 (14/14) | Loss: 0.1685 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2319/22858 (14/14) | Loss: 0.1672 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2320/22858 (14/14) | Loss: 0.1659 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2321/22858 (14/14) | Loss: 0.1653 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2322/22858 (6/14) | Loss: 0.1666 | 0.61 steps/s | Step: 352k | }Input at step 352500: virtual assistance presents on smartphone~________________________________________________________________________________________\n",
            "{| Epoch: 2322/22858 (14/14) | Loss: 0.1658 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2323/22858 (14/14) | Loss: 0.1653 | 0.60 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2324/22858 (14/14) | Loss: 0.1655 | 0.60 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2325/22858 (14/14) | Loss: 0.1654 | 0.60 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2326/22858 (14/14) | Loss: 0.1658 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2327/22858 (14/14) | Loss: 0.1670 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2328/22858 (14/14) | Loss: 0.1678 | 0.62 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2329/22858 (14/14) | Loss: 0.1679 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2330/22858 (14/14) | Loss: 0.1676 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2331/22858 (14/14) | Loss: 0.1687 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2332/22858 (14/14) | Loss: 0.1684 | 0.61 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2333/22858 (14/14) | Loss: 0.1674 | 0.60 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2334/22858 (14/14) | Loss: 0.1668 | 0.60 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2335/22858 (14/14) | Loss: 0.1669 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2336/22858 (14/14) | Loss: 0.1668 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2337/22858 (14/14) | Loss: 0.1656 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2338/22858 (14/14) | Loss: 0.1658 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2339/22858 (14/14) | Loss: 0.1658 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2340/22858 (14/14) | Loss: 0.1652 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2341/22858 (14/14) | Loss: 0.1654 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2342/22858 (14/14) | Loss: 0.1647 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2343/22858 (14/14) | Loss: 0.1656 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2344/22858 (14/14) | Loss: 0.1653 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2345/22858 (14/14) | Loss: 0.1646 | 0.58 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2346/22858 (14/14) | Loss: 0.1652 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2347/22858 (14/14) | Loss: 0.1645 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2348/22858 (14/14) | Loss: 0.1650 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2349/22858 (14/14) | Loss: 0.1649 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2350/22858 (14/14) | Loss: 0.1650 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2351/22858 (14/14) | Loss: 0.1648 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2352/22858 (14/14) | Loss: 0.1650 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2353/22858 (14/14) | Loss: 0.1639 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2354/22858 (14/14) | Loss: 0.1648 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2355/22858 (14/14) | Loss: 0.1654 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2356/22858 (14/14) | Loss: 0.1660 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2357/22858 (14/14) | Loss: 0.1656 | 0.59 steps/s | Step: 352k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2358/22858 (2/14) | Loss: 0.1662 | 0.59 steps/s | Step: 353k | }Input at step 353000: means soeone receiving medical traatmrnt from a doctor~_____________________________________________________________\n",
            "{| Epoch: 2358/22858 (14/14) | Loss: 0.1670 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2359/22858 (14/14) | Loss: 0.1662 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2360/22858 (14/14) | Loss: 0.1665 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2361/22858 (14/14) | Loss: 0.1670 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2362/22858 (14/14) | Loss: 0.1662 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2363/22858 (14/14) | Loss: 0.1663 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2364/22858 (14/14) | Loss: 0.1657 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2365/22858 (14/14) | Loss: 0.1650 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2366/22858 (14/14) | Loss: 0.1665 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2367/22858 (14/14) | Loss: 0.1670 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2368/22858 (14/14) | Loss: 0.1672 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2369/22858 (14/14) | Loss: 0.1684 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2370/22858 (14/14) | Loss: 0.1685 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2371/22858 (14/14) | Loss: 0.1685 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2372/22858 (14/14) | Loss: 0.1687 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2373/22858 (14/14) | Loss: 0.1685 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2374/22858 (14/14) | Loss: 0.1685 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2375/22858 (14/14) | Loss: 0.1689 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2376/22858 (14/14) | Loss: 0.1683 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2377/22858 (14/14) | Loss: 0.1679 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2378/22858 (14/14) | Loss: 0.1676 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2379/22858 (14/14) | Loss: 0.1672 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2380/22858 (14/14) | Loss: 0.1674 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2381/22858 (14/14) | Loss: 0.1680 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2382/22858 (14/14) | Loss: 0.1679 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2383/22858 (14/14) | Loss: 0.1676 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2384/22858 (14/14) | Loss: 0.1675 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2385/22858 (14/14) | Loss: 0.1681 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2386/22858 (14/14) | Loss: 0.1684 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2387/22858 (14/14) | Loss: 0.1685 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2388/22858 (14/14) | Loss: 0.1672 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2389/22858 (14/14) | Loss: 0.1674 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2390/22858 (14/14) | Loss: 0.1667 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2391/22858 (14/14) | Loss: 0.1657 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2392/22858 (14/14) | Loss: 0.1655 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2393/22858 (12/14) | Loss: 0.1652 | 0.58 steps/s | Step: 353k | }Input at step 353500: features these are the ways or characteristics we provide a computer to describe an example or training data~______________________\n",
            "{| Epoch: 2393/22858 (14/14) | Loss: 0.1647 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2394/22858 (14/14) | Loss: 0.1649 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2395/22858 (14/14) | Loss: 0.1646 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2396/22858 (14/14) | Loss: 0.1665 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2397/22858 (14/14) | Loss: 0.1658 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2398/22858 (14/14) | Loss: 0.1662 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2399/22858 (14/14) | Loss: 0.1662 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2400/22858 (14/14) | Loss: 0.1658 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2401/22858 (14/14) | Loss: 0.1664 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2402/22858 (14/14) | Loss: 0.1660 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2403/22858 (14/14) | Loss: 0.1658 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2404/22858 (14/14) | Loss: 0.1661 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2405/22858 (14/14) | Loss: 0.1679 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2406/22858 (14/14) | Loss: 0.1679 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2407/22858 (14/14) | Loss: 0.1692 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2408/22858 (14/14) | Loss: 0.1700 | 0.60 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2409/22858 (14/14) | Loss: 0.1705 | 0.60 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2410/22858 (14/14) | Loss: 0.1708 | 0.60 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2411/22858 (14/14) | Loss: 0.1705 | 0.60 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2412/22858 (14/14) | Loss: 0.1693 | 0.60 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2413/22858 (14/14) | Loss: 0.1692 | 0.60 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2414/22858 (14/14) | Loss: 0.1685 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2415/22858 (14/14) | Loss: 0.1682 | 0.60 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2416/22858 (14/14) | Loss: 0.1679 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2417/22858 (14/14) | Loss: 0.1689 | 0.60 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2418/22858 (14/14) | Loss: 0.1681 | 0.60 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2419/22858 (14/14) | Loss: 0.1676 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2420/22858 (14/14) | Loss: 0.1679 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2421/22858 (14/14) | Loss: 0.1675 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2422/22858 (14/14) | Loss: 0.1680 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2423/22858 (14/14) | Loss: 0.1676 | 0.59 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2424/22858 (14/14) | Loss: 0.1663 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2425/22858 (14/14) | Loss: 0.1654 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2426/22858 (14/14) | Loss: 0.1657 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2427/22858 (14/14) | Loss: 0.1659 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2428/22858 (14/14) | Loss: 0.1658 | 0.58 steps/s | Step: 353k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2429/22858 (8/14) | Loss: 0.1650 | 0.58 steps/s | Step: 354k | }Input at step 354000: this helps financial companies~_______________________________________________________________________\n",
            "{| Epoch: 2429/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2430/22858 (14/14) | Loss: 0.1655 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2431/22858 (14/14) | Loss: 0.1656 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2432/22858 (14/14) | Loss: 0.1663 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2433/22858 (14/14) | Loss: 0.1661 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2434/22858 (14/14) | Loss: 0.1653 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2435/22858 (14/14) | Loss: 0.1671 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2436/22858 (14/14) | Loss: 0.1671 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2437/22858 (14/14) | Loss: 0.1668 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2438/22858 (14/14) | Loss: 0.1667 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2439/22858 (14/14) | Loss: 0.1675 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2440/22858 (14/14) | Loss: 0.1679 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2441/22858 (14/14) | Loss: 0.1685 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2442/22858 (14/14) | Loss: 0.1668 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2443/22858 (14/14) | Loss: 0.1675 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2444/22858 (14/14) | Loss: 0.1680 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2445/22858 (14/14) | Loss: 0.1684 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2446/22858 (14/14) | Loss: 0.1682 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2447/22858 (14/14) | Loss: 0.1674 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2448/22858 (14/14) | Loss: 0.1662 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2449/22858 (14/14) | Loss: 0.1666 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2450/22858 (14/14) | Loss: 0.1661 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2451/22858 (14/14) | Loss: 0.1673 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2452/22858 (14/14) | Loss: 0.1663 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2453/22858 (14/14) | Loss: 0.1672 | 0.60 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2454/22858 (14/14) | Loss: 0.1663 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2455/22858 (14/14) | Loss: 0.1671 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2456/22858 (14/14) | Loss: 0.1667 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2457/22858 (14/14) | Loss: 0.1671 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2458/22858 (14/14) | Loss: 0.1661 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2459/22858 (14/14) | Loss: 0.1667 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2460/22858 (14/14) | Loss: 0.1663 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2461/22858 (14/14) | Loss: 0.1657 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2462/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2463/22858 (14/14) | Loss: 0.1636 | 0.57 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2464/22858 (14/14) | Loss: 0.1649 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2465/22858 (4/14) | Loss: 0.1641 | 0.57 steps/s | Step: 354k | }Input at step 354500: what is a i~___________________________________________________________________________________________\n",
            "{| Epoch: 2465/22858 (14/14) | Loss: 0.1641 | 0.57 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2466/22858 (14/14) | Loss: 0.1648 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2467/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2468/22858 (14/14) | Loss: 0.1656 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2469/22858 (14/14) | Loss: 0.1656 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2470/22858 (14/14) | Loss: 0.1657 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2471/22858 (14/14) | Loss: 0.1660 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2472/22858 (14/14) | Loss: 0.1658 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2473/22858 (14/14) | Loss: 0.1649 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2474/22858 (14/14) | Loss: 0.1660 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2475/22858 (14/14) | Loss: 0.1656 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2476/22858 (14/14) | Loss: 0.1657 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2477/22858 (14/14) | Loss: 0.1684 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2478/22858 (14/14) | Loss: 0.1680 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2479/22858 (14/14) | Loss: 0.1688 | 0.60 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2480/22858 (14/14) | Loss: 0.1681 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2481/22858 (14/14) | Loss: 0.1675 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2482/22858 (14/14) | Loss: 0.1665 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2483/22858 (14/14) | Loss: 0.1660 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2484/22858 (14/14) | Loss: 0.1650 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2485/22858 (14/14) | Loss: 0.1655 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2486/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2487/22858 (14/14) | Loss: 0.1658 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2488/22858 (14/14) | Loss: 0.1664 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2489/22858 (14/14) | Loss: 0.1669 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2490/22858 (14/14) | Loss: 0.1666 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2491/22858 (14/14) | Loss: 0.1684 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2492/22858 (14/14) | Loss: 0.1681 | 0.58 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2493/22858 (14/14) | Loss: 0.1682 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2494/22858 (14/14) | Loss: 0.1680 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2495/22858 (14/14) | Loss: 0.1685 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2496/22858 (14/14) | Loss: 0.1691 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2497/22858 (14/14) | Loss: 0.1703 | 0.60 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2498/22858 (14/14) | Loss: 0.1698 | 0.60 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2499/22858 (14/14) | Loss: 0.1686 | 0.59 steps/s | Step: 354k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2500/22858 (14/14) | Loss: 0.1683 | 0.59 steps/s | Step: 355k | }Input at step 355000: speech recognition to answer questions~_______________________________________________________________\n",
            "\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2501/22858 (14/14) | Loss: 0.1675 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2502/22858 (14/14) | Loss: 0.1681 | 0.59 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2503/22858 (14/14) | Loss: 0.1677 | 0.59 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2504/22858 (14/14) | Loss: 0.1658 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2505/22858 (14/14) | Loss: 0.1668 | 0.59 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2506/22858 (14/14) | Loss: 0.1675 | 0.59 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2507/22858 (14/14) | Loss: 0.1677 | 0.59 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2508/22858 (14/14) | Loss: 0.1677 | 0.59 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2509/22858 (14/14) | Loss: 0.1679 | 0.59 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2510/22858 (14/14) | Loss: 0.1671 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2511/22858 (14/14) | Loss: 0.1681 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2512/22858 (14/14) | Loss: 0.1665 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2513/22858 (14/14) | Loss: 0.1660 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2514/22858 (14/14) | Loss: 0.1653 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2515/22858 (14/14) | Loss: 0.1651 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2516/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2517/22858 (14/14) | Loss: 0.1670 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2518/22858 (14/14) | Loss: 0.1668 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2519/22858 (14/14) | Loss: 0.1662 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2520/22858 (14/14) | Loss: 0.1660 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2521/22858 (14/14) | Loss: 0.1649 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2522/22858 (14/14) | Loss: 0.1648 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2523/22858 (14/14) | Loss: 0.1646 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2524/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2525/22858 (14/14) | Loss: 0.1638 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2526/22858 (14/14) | Loss: 0.1651 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2527/22858 (14/14) | Loss: 0.1659 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2528/22858 (14/14) | Loss: 0.1666 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2529/22858 (14/14) | Loss: 0.1669 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2530/22858 (14/14) | Loss: 0.1678 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2531/22858 (14/14) | Loss: 0.1676 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2532/22858 (14/14) | Loss: 0.1667 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2533/22858 (14/14) | Loss: 0.1672 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2534/22858 (14/14) | Loss: 0.1660 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2535/22858 (14/14) | Loss: 0.1661 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2536/22858 (10/14) | Loss: 0.1654 | 0.56 steps/s | Step: 355k | }Input at step 355500: define machine learning~____________________________________________________________________________________\n",
            "{| Epoch: 2536/22858 (14/14) | Loss: 0.1656 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2537/22858 (14/14) | Loss: 0.1654 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2538/22858 (14/14) | Loss: 0.1646 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2539/22858 (14/14) | Loss: 0.1659 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2540/22858 (14/14) | Loss: 0.1664 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2541/22858 (14/14) | Loss: 0.1663 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2542/22858 (14/14) | Loss: 0.1668 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2543/22858 (14/14) | Loss: 0.1660 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2544/22858 (14/14) | Loss: 0.1656 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2545/22858 (14/14) | Loss: 0.1662 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2546/22858 (14/14) | Loss: 0.1662 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2547/22858 (14/14) | Loss: 0.1649 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2548/22858 (14/14) | Loss: 0.1652 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2549/22858 (14/14) | Loss: 0.1651 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2550/22858 (14/14) | Loss: 0.1650 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2551/22858 (14/14) | Loss: 0.1660 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2552/22858 (14/14) | Loss: 0.1669 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2553/22858 (14/14) | Loss: 0.1664 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2554/22858 (14/14) | Loss: 0.1663 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2555/22858 (14/14) | Loss: 0.1654 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2556/22858 (14/14) | Loss: 0.1652 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2557/22858 (14/14) | Loss: 0.1662 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2558/22858 (14/14) | Loss: 0.1658 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2559/22858 (14/14) | Loss: 0.1644 | 0.55 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2560/22858 (14/14) | Loss: 0.1648 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2561/22858 (14/14) | Loss: 0.1646 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2562/22858 (14/14) | Loss: 0.1655 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2563/22858 (14/14) | Loss: 0.1656 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2564/22858 (14/14) | Loss: 0.1667 | 0.56 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2565/22858 (14/14) | Loss: 0.1667 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2566/22858 (14/14) | Loss: 0.1673 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2567/22858 (14/14) | Loss: 0.1665 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2568/22858 (14/14) | Loss: 0.1674 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2569/22858 (14/14) | Loss: 0.1663 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2570/22858 (14/14) | Loss: 0.1676 | 0.58 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2571/22858 (14/14) | Loss: 0.1669 | 0.57 steps/s | Step: 355k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2572/22858 (6/14) | Loss: 0.1661 | 0.57 steps/s | Step: 356k | }Input at step 356000: look at the image on page nineteen~_______________________________________________________________________\n",
            "{| Epoch: 2572/22858 (14/14) | Loss: 0.1662 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2573/22858 (14/14) | Loss: 0.1671 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2574/22858 (14/14) | Loss: 0.1667 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2575/22858 (14/14) | Loss: 0.1658 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2576/22858 (14/14) | Loss: 0.1662 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2577/22858 (14/14) | Loss: 0.1666 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2578/22858 (14/14) | Loss: 0.1657 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2579/22858 (14/14) | Loss: 0.1644 | 0.56 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2580/22858 (14/14) | Loss: 0.1648 | 0.56 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2581/22858 (14/14) | Loss: 0.1654 | 0.56 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2582/22858 (14/14) | Loss: 0.1659 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2583/22858 (14/14) | Loss: 0.1655 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2584/22858 (14/14) | Loss: 0.1655 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2585/22858 (14/14) | Loss: 0.1661 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2586/22858 (14/14) | Loss: 0.1663 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2587/22858 (14/14) | Loss: 0.1667 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2588/22858 (14/14) | Loss: 0.1672 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2589/22858 (14/14) | Loss: 0.1658 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2590/22858 (14/14) | Loss: 0.1664 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2591/22858 (14/14) | Loss: 0.1658 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2592/22858 (14/14) | Loss: 0.1663 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2593/22858 (14/14) | Loss: 0.1658 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2594/22858 (14/14) | Loss: 0.1655 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2595/22858 (14/14) | Loss: 0.1658 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2596/22858 (14/14) | Loss: 0.1660 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2597/22858 (14/14) | Loss: 0.1653 | 0.57 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2598/22858 (14/14) | Loss: 0.1651 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2599/22858 (14/14) | Loss: 0.1655 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2600/22858 (14/14) | Loss: 0.1641 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2601/22858 (14/14) | Loss: 0.1634 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2602/22858 (14/14) | Loss: 0.1630 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2603/22858 (14/14) | Loss: 0.1645 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2604/22858 (14/14) | Loss: 0.1656 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2605/22858 (14/14) | Loss: 0.1654 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2606/22858 (14/14) | Loss: 0.1656 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2607/22858 (14/14) | Loss: 0.1665 | 0.60 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2608/22858 (2/14) | Loss: 0.1660 | 0.59 steps/s | Step: 356k | }Input at step 356500: four modelling~______________________________________________________________________________________________\n",
            "{| Epoch: 2608/22858 (14/14) | Loss: 0.1673 | 0.60 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2609/22858 (14/14) | Loss: 0.1664 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2610/22858 (14/14) | Loss: 0.1664 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2611/22858 (14/14) | Loss: 0.1659 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2612/22858 (14/14) | Loss: 0.1652 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2613/22858 (14/14) | Loss: 0.1654 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2614/22858 (14/14) | Loss: 0.1662 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2615/22858 (14/14) | Loss: 0.1651 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2616/22858 (14/14) | Loss: 0.1657 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2617/22858 (14/14) | Loss: 0.1664 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2618/22858 (14/14) | Loss: 0.1665 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2619/22858 (14/14) | Loss: 0.1667 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2620/22858 (14/14) | Loss: 0.1656 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2621/22858 (14/14) | Loss: 0.1655 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2622/22858 (14/14) | Loss: 0.1657 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2623/22858 (14/14) | Loss: 0.1650 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2624/22858 (14/14) | Loss: 0.1639 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2625/22858 (14/14) | Loss: 0.1637 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2626/22858 (14/14) | Loss: 0.1635 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2627/22858 (14/14) | Loss: 0.1633 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2628/22858 (14/14) | Loss: 0.1632 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2629/22858 (14/14) | Loss: 0.1636 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2630/22858 (14/14) | Loss: 0.1627 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2631/22858 (14/14) | Loss: 0.1633 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2632/22858 (14/14) | Loss: 0.1630 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2633/22858 (14/14) | Loss: 0.1641 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2634/22858 (14/14) | Loss: 0.1644 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2635/22858 (14/14) | Loss: 0.1661 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2636/22858 (14/14) | Loss: 0.1663 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2637/22858 (14/14) | Loss: 0.1661 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2638/22858 (14/14) | Loss: 0.1675 | 0.60 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2639/22858 (14/14) | Loss: 0.1668 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2640/22858 (14/14) | Loss: 0.1659 | 0.59 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2641/22858 (14/14) | Loss: 0.1654 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2642/22858 (14/14) | Loss: 0.1655 | 0.58 steps/s | Step: 356k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2643/22858 (12/14) | Loss: 0.1650 | 0.58 steps/s | Step: 357k | }Input at step 357000: to help bassey find his toy~_____________________________________________________________\n",
            "{| Epoch: 2643/22858 (14/14) | Loss: 0.1651 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2644/22858 (14/14) | Loss: 0.1648 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2645/22858 (14/14) | Loss: 0.1657 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2646/22858 (14/14) | Loss: 0.1654 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2647/22858 (14/14) | Loss: 0.1667 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2648/22858 (14/14) | Loss: 0.1654 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2649/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2650/22858 (14/14) | Loss: 0.1656 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2651/22858 (14/14) | Loss: 0.1650 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2652/22858 (14/14) | Loss: 0.1650 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2653/22858 (14/14) | Loss: 0.1634 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2654/22858 (14/14) | Loss: 0.1639 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2655/22858 (14/14) | Loss: 0.1636 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2656/22858 (14/14) | Loss: 0.1646 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2657/22858 (14/14) | Loss: 0.1642 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2658/22858 (14/14) | Loss: 0.1635 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2659/22858 (14/14) | Loss: 0.1641 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2660/22858 (14/14) | Loss: 0.1643 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2661/22858 (14/14) | Loss: 0.1645 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2662/22858 (14/14) | Loss: 0.1653 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2663/22858 (14/14) | Loss: 0.1657 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2664/22858 (14/14) | Loss: 0.1656 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2665/22858 (14/14) | Loss: 0.1655 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2666/22858 (14/14) | Loss: 0.1668 | 0.60 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2667/22858 (14/14) | Loss: 0.1668 | 0.60 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2668/22858 (14/14) | Loss: 0.1670 | 0.60 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2669/22858 (14/14) | Loss: 0.1660 | 0.60 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2670/22858 (14/14) | Loss: 0.1662 | 0.60 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2671/22858 (14/14) | Loss: 0.1671 | 0.60 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2672/22858 (14/14) | Loss: 0.1676 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2673/22858 (14/14) | Loss: 0.1672 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2674/22858 (14/14) | Loss: 0.1673 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2675/22858 (14/14) | Loss: 0.1665 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2676/22858 (14/14) | Loss: 0.1660 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2677/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2678/22858 (14/14) | Loss: 0.1640 | 0.57 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2679/22858 (8/14) | Loss: 0.1650 | 0.57 steps/s | Step: 357k | }Input at step 357500: or no points assigned if it is a no~____________________________________________\n",
            "{| Epoch: 2679/22858 (14/14) | Loss: 0.1648 | 0.57 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2680/22858 (14/14) | Loss: 0.1641 | 0.57 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2681/22858 (14/14) | Loss: 0.1644 | 0.57 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2682/22858 (14/14) | Loss: 0.1642 | 0.57 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2683/22858 (14/14) | Loss: 0.1644 | 0.57 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2684/22858 (14/14) | Loss: 0.1645 | 0.57 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2685/22858 (14/14) | Loss: 0.1651 | 0.57 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2686/22858 (14/14) | Loss: 0.1646 | 0.57 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2687/22858 (14/14) | Loss: 0.1636 | 0.57 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2688/22858 (14/14) | Loss: 0.1642 | 0.57 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2689/22858 (14/14) | Loss: 0.1649 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2690/22858 (14/14) | Loss: 0.1648 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2691/22858 (14/14) | Loss: 0.1642 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2692/22858 (14/14) | Loss: 0.1648 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2693/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2694/22858 (14/14) | Loss: 0.1655 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2695/22858 (14/14) | Loss: 0.1660 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2696/22858 (14/14) | Loss: 0.1664 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2697/22858 (14/14) | Loss: 0.1665 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2698/22858 (14/14) | Loss: 0.1676 | 0.59 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2699/22858 (14/14) | Loss: 0.1673 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2700/22858 (14/14) | Loss: 0.1668 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2701/22858 (14/14) | Loss: 0.1663 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2702/22858 (14/14) | Loss: 0.1657 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2703/22858 (14/14) | Loss: 0.1657 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2704/22858 (14/14) | Loss: 0.1654 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2705/22858 (14/14) | Loss: 0.1652 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2706/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2707/22858 (14/14) | Loss: 0.1661 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2708/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2709/22858 (14/14) | Loss: 0.1648 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2710/22858 (14/14) | Loss: 0.1639 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2711/22858 (14/14) | Loss: 0.1651 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2712/22858 (14/14) | Loss: 0.1645 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2713/22858 (14/14) | Loss: 0.1650 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2714/22858 (14/14) | Loss: 0.1648 | 0.58 steps/s | Step: 357k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2715/22858 (4/14) | Loss: 0.1645 | 0.58 steps/s | Step: 358k | }Input at step 358000: type of foods the person eats~__________________________________________________________________________\n",
            "{| Epoch: 2715/22858 (14/14) | Loss: 0.1656 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2716/22858 (14/14) | Loss: 0.1658 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2717/22858 (14/14) | Loss: 0.1658 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2718/22858 (14/14) | Loss: 0.1646 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2719/22858 (14/14) | Loss: 0.1641 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2720/22858 (14/14) | Loss: 0.1638 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2721/22858 (14/14) | Loss: 0.1646 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2722/22858 (14/14) | Loss: 0.1631 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2723/22858 (14/14) | Loss: 0.1637 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2724/22858 (14/14) | Loss: 0.1638 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2725/22858 (14/14) | Loss: 0.1638 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2726/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2727/22858 (14/14) | Loss: 0.1656 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2728/22858 (14/14) | Loss: 0.1645 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2729/22858 (14/14) | Loss: 0.1655 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2730/22858 (14/14) | Loss: 0.1642 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2731/22858 (14/14) | Loss: 0.1643 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2732/22858 (14/14) | Loss: 0.1645 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2733/22858 (14/14) | Loss: 0.1644 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2734/22858 (14/14) | Loss: 0.1648 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2735/22858 (14/14) | Loss: 0.1643 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2736/22858 (14/14) | Loss: 0.1644 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2737/22858 (14/14) | Loss: 0.1639 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2738/22858 (14/14) | Loss: 0.1640 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2739/22858 (14/14) | Loss: 0.1643 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2740/22858 (14/14) | Loss: 0.1632 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2741/22858 (14/14) | Loss: 0.1621 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2742/22858 (14/14) | Loss: 0.1632 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2743/22858 (14/14) | Loss: 0.1628 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2744/22858 (14/14) | Loss: 0.1636 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2745/22858 (14/14) | Loss: 0.1628 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2746/22858 (14/14) | Loss: 0.1637 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2747/22858 (14/14) | Loss: 0.1640 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2748/22858 (14/14) | Loss: 0.1633 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2749/22858 (14/14) | Loss: 0.1632 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2750/22858 (14/14) | Loss: 0.1636 | 0.57 steps/s | Step: 358k | }Input at step 358500: same for the three's as you can see on your screen~__________________________________________\n",
            "\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2751/22858 (14/14) | Loss: 0.1639 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2752/22858 (14/14) | Loss: 0.1652 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2753/22858 (14/14) | Loss: 0.1648 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2754/22858 (14/14) | Loss: 0.1654 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2755/22858 (14/14) | Loss: 0.1665 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2756/22858 (14/14) | Loss: 0.1653 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2757/22858 (14/14) | Loss: 0.1649 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2758/22858 (14/14) | Loss: 0.1635 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2759/22858 (14/14) | Loss: 0.1622 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2760/22858 (14/14) | Loss: 0.1621 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2761/22858 (14/14) | Loss: 0.1619 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2762/22858 (14/14) | Loss: 0.1621 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2763/22858 (14/14) | Loss: 0.1627 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2764/22858 (14/14) | Loss: 0.1628 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2765/22858 (14/14) | Loss: 0.1632 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2766/22858 (14/14) | Loss: 0.1626 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2767/22858 (14/14) | Loss: 0.1621 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2768/22858 (14/14) | Loss: 0.1616 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2769/22858 (14/14) | Loss: 0.1619 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2770/22858 (14/14) | Loss: 0.1622 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2771/22858 (14/14) | Loss: 0.1625 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2772/22858 (14/14) | Loss: 0.1621 | 0.57 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2773/22858 (14/14) | Loss: 0.1636 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2774/22858 (14/14) | Loss: 0.1642 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2775/22858 (14/14) | Loss: 0.1659 | 0.59 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2776/22858 (14/14) | Loss: 0.1653 | 0.59 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2777/22858 (14/14) | Loss: 0.1658 | 0.59 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2778/22858 (14/14) | Loss: 0.1661 | 0.59 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2779/22858 (14/14) | Loss: 0.1664 | 0.59 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2780/22858 (14/14) | Loss: 0.1664 | 0.60 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2781/22858 (14/14) | Loss: 0.1669 | 0.60 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2782/22858 (14/14) | Loss: 0.1666 | 0.59 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2783/22858 (14/14) | Loss: 0.1660 | 0.59 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2784/22858 (14/14) | Loss: 0.1657 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2785/22858 (14/14) | Loss: 0.1660 | 0.58 steps/s | Step: 358k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2786/22858 (10/14) | Loss: 0.1657 | 0.57 steps/s | Step: 359k | }Input at step 359000: solving math's problem and flipping tv channels all without saying a word~__________________________________\n",
            "{| Epoch: 2786/22858 (14/14) | Loss: 0.1663 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2787/22858 (14/14) | Loss: 0.1647 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2788/22858 (14/14) | Loss: 0.1643 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2789/22858 (14/14) | Loss: 0.1639 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2790/22858 (14/14) | Loss: 0.1634 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2791/22858 (14/14) | Loss: 0.1636 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2792/22858 (14/14) | Loss: 0.1633 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2793/22858 (14/14) | Loss: 0.1629 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2794/22858 (14/14) | Loss: 0.1634 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2795/22858 (14/14) | Loss: 0.1631 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2796/22858 (14/14) | Loss: 0.1616 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2797/22858 (14/14) | Loss: 0.1622 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2798/22858 (14/14) | Loss: 0.1623 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2799/22858 (14/14) | Loss: 0.1617 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2800/22858 (14/14) | Loss: 0.1618 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2801/22858 (14/14) | Loss: 0.1623 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2802/22858 (14/14) | Loss: 0.1628 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2803/22858 (14/14) | Loss: 0.1643 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2804/22858 (14/14) | Loss: 0.1639 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2805/22858 (14/14) | Loss: 0.1646 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2806/22858 (14/14) | Loss: 0.1647 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2807/22858 (14/14) | Loss: 0.1649 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2808/22858 (14/14) | Loss: 0.1650 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2809/22858 (14/14) | Loss: 0.1632 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2810/22858 (14/14) | Loss: 0.1641 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2811/22858 (14/14) | Loss: 0.1647 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2812/22858 (14/14) | Loss: 0.1640 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2813/22858 (14/14) | Loss: 0.1635 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2814/22858 (14/14) | Loss: 0.1644 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2815/22858 (14/14) | Loss: 0.1633 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2816/22858 (14/14) | Loss: 0.1634 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2817/22858 (14/14) | Loss: 0.1643 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2818/22858 (14/14) | Loss: 0.1635 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2819/22858 (14/14) | Loss: 0.1642 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2820/22858 (14/14) | Loss: 0.1642 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2821/22858 (14/14) | Loss: 0.1646 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2822/22858 (6/14) | Loss: 0.1642 | 0.58 steps/s | Step: 359k | }Input at step 359500: you're inquisitive~_______________________________________________________________________________________________________________\n",
            "{| Epoch: 2822/22858 (14/14) | Loss: 0.1642 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2823/22858 (14/14) | Loss: 0.1639 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2824/22858 (14/14) | Loss: 0.1641 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2825/22858 (14/14) | Loss: 0.1641 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2826/22858 (14/14) | Loss: 0.1630 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2827/22858 (14/14) | Loss: 0.1635 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2828/22858 (14/14) | Loss: 0.1647 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2829/22858 (14/14) | Loss: 0.1638 | 0.55 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2830/22858 (14/14) | Loss: 0.1663 | 0.55 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2831/22858 (14/14) | Loss: 0.1654 | 0.55 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2832/22858 (14/14) | Loss: 0.1659 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2833/22858 (14/14) | Loss: 0.1664 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2834/22858 (14/14) | Loss: 0.1671 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2835/22858 (14/14) | Loss: 0.1660 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2836/22858 (14/14) | Loss: 0.1664 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2837/22858 (14/14) | Loss: 0.1658 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2838/22858 (14/14) | Loss: 0.1650 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2839/22858 (14/14) | Loss: 0.1651 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2840/22858 (14/14) | Loss: 0.1655 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2841/22858 (14/14) | Loss: 0.1654 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2842/22858 (14/14) | Loss: 0.1650 | 0.55 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2843/22858 (14/14) | Loss: 0.1653 | 0.55 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2844/22858 (14/14) | Loss: 0.1646 | 0.55 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2845/22858 (14/14) | Loss: 0.1632 | 0.55 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2846/22858 (14/14) | Loss: 0.1635 | 0.55 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2847/22858 (14/14) | Loss: 0.1628 | 0.55 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2848/22858 (14/14) | Loss: 0.1638 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2849/22858 (14/14) | Loss: 0.1626 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2850/22858 (14/14) | Loss: 0.1632 | 0.56 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2851/22858 (14/14) | Loss: 0.1640 | 0.57 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2852/22858 (14/14) | Loss: 0.1660 | 0.58 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2853/22858 (14/14) | Loss: 0.1664 | 0.59 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2854/22858 (14/14) | Loss: 0.1668 | 0.59 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2855/22858 (14/14) | Loss: 0.1671 | 0.59 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2856/22858 (14/14) | Loss: 0.1679 | 0.60 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2857/22858 (14/14) | Loss: 0.1686 | 0.60 steps/s | Step: 359k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2858/22858 (2/14) | Loss: 0.1678 | 0.60 steps/s | Step: 360k | }Input at step 360000: all the number one's are put together~______________________________________________________\n",
            "{| Epoch: 2858/22858 (14/14) | Loss: 0.1679 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2859/22858 (14/14) | Loss: 0.1664 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2860/22858 (14/14) | Loss: 0.1660 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2861/22858 (14/14) | Loss: 0.1651 | 0.57 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2862/22858 (14/14) | Loss: 0.1655 | 0.56 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2863/22858 (14/14) | Loss: 0.1650 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2864/22858 (14/14) | Loss: 0.1642 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2865/22858 (14/14) | Loss: 0.1642 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2866/22858 (14/14) | Loss: 0.1643 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2867/22858 (14/14) | Loss: 0.1646 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2868/22858 (14/14) | Loss: 0.1648 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2869/22858 (14/14) | Loss: 0.1652 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2870/22858 (14/14) | Loss: 0.1647 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2871/22858 (14/14) | Loss: 0.1644 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2872/22858 (14/14) | Loss: 0.1640 | 0.56 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2873/22858 (14/14) | Loss: 0.1637 | 0.56 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2874/22858 (14/14) | Loss: 0.1629 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2875/22858 (14/14) | Loss: 0.1632 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2876/22858 (14/14) | Loss: 0.1631 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2877/22858 (14/14) | Loss: 0.1623 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2878/22858 (14/14) | Loss: 0.1623 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2879/22858 (14/14) | Loss: 0.1626 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2880/22858 (14/14) | Loss: 0.1623 | 0.54 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2881/22858 (14/14) | Loss: 0.1621 | 0.54 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2882/22858 (14/14) | Loss: 0.1623 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2883/22858 (14/14) | Loss: 0.1621 | 0.55 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2884/22858 (14/14) | Loss: 0.1633 | 0.56 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2885/22858 (14/14) | Loss: 0.1635 | 0.57 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2886/22858 (14/14) | Loss: 0.1637 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2887/22858 (14/14) | Loss: 0.1645 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2888/22858 (14/14) | Loss: 0.1640 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2889/22858 (14/14) | Loss: 0.1647 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2890/22858 (14/14) | Loss: 0.1650 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2891/22858 (14/14) | Loss: 0.1644 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2892/22858 (14/14) | Loss: 0.1646 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2893/22858 (12/14) | Loss: 0.1645 | 0.58 steps/s | Step: 360k | }Input at step 360500: if the robot succeeds we will reward it~______________________________________________________________\n",
            "{| Epoch: 2893/22858 (14/14) | Loss: 0.1651 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2894/22858 (14/14) | Loss: 0.1643 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2895/22858 (14/14) | Loss: 0.1654 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2896/22858 (14/14) | Loss: 0.1650 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2897/22858 (14/14) | Loss: 0.1651 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2898/22858 (14/14) | Loss: 0.1644 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2899/22858 (14/14) | Loss: 0.1647 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2900/22858 (14/14) | Loss: 0.1646 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2901/22858 (14/14) | Loss: 0.1649 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2902/22858 (14/14) | Loss: 0.1646 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2903/22858 (14/14) | Loss: 0.1649 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2904/22858 (14/14) | Loss: 0.1654 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2905/22858 (14/14) | Loss: 0.1653 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2906/22858 (14/14) | Loss: 0.1656 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2907/22858 (14/14) | Loss: 0.1660 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2908/22858 (14/14) | Loss: 0.1658 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2909/22858 (14/14) | Loss: 0.1645 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2910/22858 (14/14) | Loss: 0.1645 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2911/22858 (14/14) | Loss: 0.1630 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2912/22858 (14/14) | Loss: 0.1619 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2913/22858 (14/14) | Loss: 0.1614 | 0.57 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2914/22858 (14/14) | Loss: 0.1613 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2915/22858 (14/14) | Loss: 0.1608 | 0.57 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2916/22858 (14/14) | Loss: 0.1622 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2917/22858 (14/14) | Loss: 0.1638 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2918/22858 (14/14) | Loss: 0.1642 | 0.58 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2919/22858 (14/14) | Loss: 0.1643 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2920/22858 (14/14) | Loss: 0.1650 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2921/22858 (14/14) | Loss: 0.1647 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2922/22858 (14/14) | Loss: 0.1644 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2923/22858 (14/14) | Loss: 0.1639 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2924/22858 (14/14) | Loss: 0.1636 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2925/22858 (14/14) | Loss: 0.1633 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2926/22858 (14/14) | Loss: 0.1643 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2927/22858 (14/14) | Loss: 0.1639 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2928/22858 (14/14) | Loss: 0.1643 | 0.59 steps/s | Step: 360k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2929/22858 (8/14) | Loss: 0.1657 | 0.59 steps/s | Step: 361k | }Input at step 361000: the first step to be taken in training our robot is by collecting diffrent handwritten digit from people~___________\n",
            "{| Epoch: 2929/22858 (14/14) | Loss: 0.1658 | 0.59 steps/s | Step: 361k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2930/22858 (14/14) | Loss: 0.1664 | 0.59 steps/s | Step: 361k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2931/22858 (14/14) | Loss: 0.1657 | 0.59 steps/s | Step: 361k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2932/22858 (5/14) | Loss: 0.1655 | 0.59 steps/s | Step: 361k | }"
          ]
        }
      ],
      "source": [
        "!python synthesizer_train.py synthesizer synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer -s 200 -b 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxpberM3k8OW",
        "outputId": "b821cd1b-04ba-4a6c-ac16-6b528653e5bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    run_id:          pretrained_original\n",
            "    syn_dir:         synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer\n",
            "    models_dir:      synthesizer/saved_models/\n",
            "    save_every:      125\n",
            "    backup_every:    100\n",
            "    force_restart:   False\n",
            "    hparams:         \n",
            "\n",
            "Checkpoint path: synthesizer/saved_models/pretrained_original/pretrained_original.pt\n",
            "Loading training data from: synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer/train.txt\n",
            "Using model: Tacotron\n",
            "Using device: cuda\n",
            "\n",
            "Initialising Tacotron Model...\n",
            "\n",
            "Trainable Parameters: 30.870M\n",
            "\n",
            "Starting the training of Tacotron from scratch\n",
            "\n",
            "Using inputs from:\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer/train.txt\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer/mels\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer/embeds\n",
            "Found 868 samples\n",
            "+----------------+------------+---------------+------------------+\n",
            "| Steps with r=2 | Batch Size | Learning Rate | Outputs/Step (r) |\n",
            "+----------------+------------+---------------+------------------+\n",
            "|   20k Steps    |     64     |     0.001     |        2         |\n",
            "+----------------+------------+---------------+------------------+\n",
            " \n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 1/1429 (14/14) | Loss: 8.679 | 0.43 steps/s | Step: 0k | }\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/synthesizer_dataset.py:84: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  embeds = torch.tensor(embeds)\n",
            "{| Epoch: 2/1429 (11/14) | Loss: 5.767 | 0.46 steps/s | Step: 0k | }"
          ]
        }
      ],
      "source": [
        "!python synthesizer_train.py pretrained_original synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_female/synthesizer -s 125 -b 100 #--checkpoint_interval 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAbIRMvHyHVl"
      },
      "source": [
        "##### male"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBWOScyPTGq1",
        "outputId": "ed64adb6-a67e-45c2-9e5e-554e1d375517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"synthesizer_preprocess_audio.py\", line 1, in <module>\n",
            "    from synthesizer.preprocess import preprocess_dataset\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/preprocess.py\", line 5, in <module>\n",
            "    from encoder import inference as encoder\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/VoiceCloning/Real-Time-Voice-Cloning/encoder/inference.py\", line 2, in <module>\n",
            "    from encoder.model import SpeakerEncoder\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/VoiceCloning/Real-Time-Voice-Cloning/encoder/model.py\", line 5, in <module>\n",
            "    from torch.nn.utils import clip_grad_norm_\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/__init__.py\", line 197, in <module>\n",
            "    from torch._C import *  # noqa: F403\n",
            "RuntimeError: KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "!python synthesizer_preprocess_audio.py '/content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root' --datasets_name 'Dr_BayoSample_voice' --subfolders 'ljs' -o \"/content/drive/MyDrive/VoiceCloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_newest45\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZteKE2vZC4K",
        "outputId": "303134f8-1731-415d-d290-7c6bca8da19f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    synthesizer_root:      /content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_newest/synthesizer\n",
            "    encoder_model_fpath:   /content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/encoder/saved_models/pretrained_backups/pretrained_bak_1684610.pt\n",
            "    n_processes:           4\n",
            "\n",
            "\rEmbedding:   0% 0/684 [00:00<?, ?utterances/s]Loaded encoder \"pretrained_bak_1684610.pt\" trained to step 1684611\n",
            "Loaded encoder \"pretrained_bak_1684610.pt\" trained to step 1684611\n",
            "Loaded encoder \"pretrained_bak_1684610.pt\" trained to step 1684611\n",
            "Loaded encoder \"pretrained_bak_1684610.pt\" trained to step 1684611\n",
            "Embedding: 100% 684/684 [00:42<00:00, 16.17utterances/s]\n"
          ]
        }
      ],
      "source": [
        "!python synthesizer_preprocess_embeds.py \"/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_newest/synthesizer\" -e \"/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/encoder/saved_models/pretrained_backups/pretrained_bak_1684610.pt\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "TVOSjPf9iOz6",
        "outputId": "86cda42c-4029-4946-c07e-5cd43bd4f425"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd 5599, 476k,515k.521 to pretrained\n",
        "checkpoint 320k,395k,442"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzMV4q8Ibjyf",
        "outputId": "7d1b3f64-1633-4096-90cf-04ef9d36919a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    run_id:          pretrained\n",
            "    syn_dir:         /content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_newest/synthesizer\n",
            "    models_dir:      synthesizer/saved_models/\n",
            "    save_every:      200\n",
            "    backup_every:    1000\n",
            "    force_restart:   False\n",
            "    hparams:         \n",
            "\n",
            "Checkpoint path: synthesizer/saved_models/pretrained/pretrained.pt\n",
            "Loading training data from: /content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_newest/synthesizer/train.txt\n",
            "Using model: Tacotron\n",
            "Using device: cuda\n",
            "\n",
            "Initialising Tacotron Model...\n",
            "\n",
            "Trainable Parameters: 30.870M\n",
            "\n",
            "Loading weights at synthesizer/saved_models/pretrained/pretrained.pt\n",
            "Tacotron weights loaded from step 640000\n",
            "Using inputs from:\n",
            "\t/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_newest/synthesizer/train.txt\n",
            "\t/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_newest/synthesizer/mels\n",
            "\t/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_newest/synthesizer/embeds\n",
            "Found 684 samples\n"
          ]
        }
      ],
      "source": [
        "!python synthesizer_train.py pretrained \"/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS_newest/synthesizer\" -s 200 -b 1000 #--checkpoint_interval 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSK0wwpVblJT"
      },
      "source": [
        "## Pretrained Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xp5_wsYNjvJ",
        "outputId": "e3cf7011-5137-4a5c-ab32-7df7eebd3941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"synthesizer_preprocess_audio.py\", line 1, in <module>\n",
            "    from synthesizer.preprocess import preprocess_dataset\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/preprocess.py\", line 2, in <module>\n",
            "    from synthesizer import audio\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/audio.py\", line 1, in <module>\n",
            "    import librosa\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/librosa/__init__.py\", line 211, in <module>\n",
            "    from . import core\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/librosa/core/__init__.py\", line 5, in <module>\n",
            "    from .convert import *  # pylint: disable=wildcard-import\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/librosa/core/convert.py\", line 7, in <module>\n",
            "    from . import notation\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/librosa/core/notation.py\", line 8, in <module>\n",
            "    from ..util.exceptions import ParameterError\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/librosa/util/__init__.py\", line 83, in <module>\n",
            "    from .utils import *  # pylint: disable=wildcard-import\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/librosa/util/utils.py\", line 10, in <module>\n",
            "    import numba\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/__init__.py\", line 213, in <module>\n",
            "    import numba.typed\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/typed/__init__.py\", line 1, in <module>\n",
            "    from .typeddict import Dict\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/typed/typeddict.py\", line 22, in <module>\n",
            "    @njit\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/decorators.py\", line 257, in njit\n",
            "    return jit(*args, **kws)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/decorators.py\", line 180, in jit\n",
            "    return wrapper(pyfunc)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/decorators.py\", line 209, in wrapper\n",
            "    **dispatcher_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py\", line 708, in __init__\n",
            "    self.targetctx = self.targetdescr.target_context\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/registry.py\", line 47, in target_context\n",
            "    return self._toplevel_target_context\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/utils.py\", line 349, in __get__\n",
            "    res = instance.__dict__[self.name] = self.func(instance)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/registry.py\", line 31, in _toplevel_target_context\n",
            "    return cpu.CPUContext(self.typing_context)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/base.py\", line 259, in __init__\n",
            "    self.init()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py\", line 32, in _acquire_compile_lock\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/cpu.py\", line 57, in init\n",
            "    rtsys.initialize(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py\", line 32, in _acquire_compile_lock\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/runtime/nrt.py\", line 37, in initialize\n",
            "    self._library = nrtdynmod.compile_nrt_functions(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/runtime/nrtdynmod.py\", line 209, in compile_nrt_functions\n",
            "    library.add_ir_module(ir_mod)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/codegen.py\", line 209, in add_ir_module\n",
            "    self.add_llvm_module(ll_module)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/codegen.py\", line 212, in add_llvm_module\n",
            "    self._optimize_functions(ll_module)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numba/core/codegen.py\", line 138, in _optimize_functions\n",
            "    fpm.run(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/llvmlite/binding/passmanagers.py\", line 126, in run\n",
            "    return ffi.lib.LLVMPY_RunFunctionPassManager(self, function)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/llvmlite/binding/ffi.py\", line 113, in __call__\n",
            "    return self._cfn(*args, **kwargs)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python synthesizer_preprocess_audio.py '/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root' --datasets_name 'Dr_BayoSample_voice' --subfolders 'ljs' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34nb_1neGReD",
        "outputId": "cc78dae4-3260-48a5-ba17-867304cac1a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-11-04 08:57:27--  https://github.com/blue-fish/Real-Time-Voice-Cloning/releases/download/v1.0/pretrained.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/274049886/9764da00-6919-11eb-8444-e8027183f04f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211104%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211104T085727Z&X-Amz-Expires=300&X-Amz-Signature=08003ccbdd0f16284f82109d03ab9a5f8c5d64423de125d0451b2689363388af&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=274049886&response-content-disposition=attachment%3B%20filename%3Dpretrained.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-11-04 08:57:27--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/274049886/9764da00-6919-11eb-8444-e8027183f04f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211104%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211104T085727Z&X-Amz-Expires=300&X-Amz-Signature=08003ccbdd0f16284f82109d03ab9a5f8c5d64423de125d0451b2689363388af&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=274049886&response-content-disposition=attachment%3B%20filename%3Dpretrained.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 397171814 (379M) [application/octet-stream]\n",
            "Saving to: ‘pretrained.zip.1’\n",
            "\n",
            "pretrained.zip.1    100%[===================>] 378.77M  39.3MB/s    in 10s     \n",
            "\n",
            "2021-11-04 08:57:46 (36.8 MB/s) - ‘pretrained.zip.1’ saved [397171814/397171814]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/blue-fish/Real-Time-Voice-Cloning/releases/download/v1.0/pretrained.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRvOoBN2OcB2",
        "outputId": "f2678977-ec94-4abb-bbd6-83e16d6854e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " demo_cli.py\t\t synthesizer_preprocess_audio.py\n",
            " demo_toolbox.py\t synthesizer_preprocess_embeds.py\n",
            "'Dr Bayo 1hr.wav'\t synthesizer_train.py\n",
            " encoder\t\t textgrid.py\n",
            " encoder_preprocess.py\t TextGrid.txt\n",
            " encoder_train.py\t toolbox\n",
            " LICENSE.txt\t\t tts-voicesample01_QqV9DliK.wav\n",
            " pretrained.zip\t\t tts-voicesample301_sdBTm5U0.wav\n",
            " __pycache__\t\t utils\n",
            " README.md\t\t vocoder\n",
            " requirements.txt\t vocoder_preprocess.py\n",
            " result\t\t\t vocoder_train.py\n",
            " samples\t\t word_align.txt\n",
            " synthesizer\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kqgxg5FzGugC"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl8C-lfFGwO8"
      },
      "outputs": [],
      "source": [
        "with ZipFile('pretrained.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XsVShNEDNmD",
        "outputId": "be463f31-e2a0-44f6-b3af-421df044c5d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    synthesizer_root:      /content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer\n",
            "    encoder_model_fpath:   encoder/saved_models/pretrained.pt\n",
            "    n_processes:           4\n",
            "\n",
            "\rEmbedding:   0% 0/684 [00:00<?, ?utterances/s]Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
            "Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
            "Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
            "Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
            "Embedding: 100% 684/684 [05:54<00:00,  1.93utterances/s]\n"
          ]
        }
      ],
      "source": [
        "!python synthesizer_preprocess_embeds.py '/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lsq_YO-YJdAh",
        "outputId": "7fe23655-98e4-424c-a6d1-bde2c65f244d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    run_id:          pretrained\n",
            "    syn_dir:         synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer\n",
            "    models_dir:      synthesizer/saved_models/\n",
            "    save_every:      200\n",
            "    backup_every:    100\n",
            "    force_restart:   False\n",
            "    hparams:         \n",
            "\n",
            "Checkpoint path: synthesizer/saved_models/pretrained/pretrained_327k.pt\n",
            "Loading training data from: synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/train.txt\n",
            "Using model: Tacotron\n",
            "Using device: cuda\n",
            "\n",
            "Initialising Tacotron Model...\n",
            "\n",
            "Trainable Parameters: 30.870M\n",
            "\n",
            "Loading weights at synthesizer/saved_models/pretrained/pretrained_327k.pt\n",
            "Tacotron weights loaded from step 1800\n",
            "Using inputs from:\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/train.txt\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/mels\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/embeds\n",
            "Found 684 samples\n",
            "+----------------+------------+---------------+------------------+\n",
            "| Steps with r=2 | Batch Size | Learning Rate | Outputs/Step (r) |\n",
            "+----------------+------------+---------------+------------------+\n",
            "|   18k Steps    |     12     |     0.001     |        2         |\n",
            "+----------------+------------+---------------+------------------+\n",
            " \n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "{| Epoch: 1/320 (57/57) | Loss: 0.7697 | 1.4 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 2/320 (57/57) | Loss: 0.7561 | 1.4 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 3/320 (57/57) | Loss: 0.7348 | 1.4 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 4/320 (29/57) | Loss: 0.7216 | 1.3 steps/s | Step: 2k | }Input at step 2000: who is our finance guy for data science nigeria~______________\n",
            "{| Epoch: 4/320 (57/57) | Loss: 0.7279 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 5/320 (57/57) | Loss: 0.7218 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 6/320 (57/57) | Loss: 0.7219 | 1.4 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 7/320 (57/57) | Loss: 0.7098 | 1.4 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 8/320 (57/57) | Loss: 0.6978 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 9/320 (57/57) | Loss: 0.6850 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 10/320 (57/57) | Loss: 0.6772 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 11/320 (57/57) | Loss: 0.6806 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 12/320 (57/57) | Loss: 0.6704 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 13/320 (16/57) | Loss: 0.6702 | 1.3 steps/s | Step: 2k | }Input at step 2500: since we know they are home we wanted to engage them~_______________________\n",
            "{| Epoch: 13/320 (57/57) | Loss: 0.6622 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 14/320 (57/57) | Loss: 0.6646 | 1.4 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 15/320 (57/57) | Loss: 0.6595 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 16/320 (57/57) | Loss: 0.6472 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 17/320 (57/57) | Loss: 0.6422 | 1.4 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 18/320 (57/57) | Loss: 0.6196 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 19/320 (57/57) | Loss: 0.6249 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 20/320 (57/57) | Loss: 0.6165 | 1.4 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 21/320 (57/57) | Loss: 0.6072 | 1.3 steps/s | Step: 2k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 22/320 (3/57) | Loss: 0.6054 | 1.3 steps/s | Step: 3k | }Input at step 3000: machine can learn the pattern of those things~__________________________________________________________________________\n",
            "{| Epoch: 22/320 (57/57) | Loss: 0.6108 | 1.3 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 23/320 (57/57) | Loss: 0.6230 | 1.4 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 24/320 (57/57) | Loss: 0.6141 | 1.4 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 25/320 (57/57) | Loss: 0.5967 | 1.3 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 26/320 (57/57) | Loss: 0.5816 | 1.3 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 27/320 (57/57) | Loss: 0.5738 | 1.3 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 28/320 (57/57) | Loss: 0.5756 | 1.4 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 29/320 (57/57) | Loss: 0.5691 | 1.4 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 30/320 (47/57) | Loss: 0.5673 | 1.3 steps/s | Step: 3k | }Input at step 3500: you know they are very curious they've got energy and they are very creative based on the learning that i have seen~\n",
            "{| Epoch: 30/320 (57/57) | Loss: 0.5590 | 1.3 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 31/320 (57/57) | Loss: 0.5511 | 1.3 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 32/320 (57/57) | Loss: 0.5605 | 1.3 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 33/320 (57/57) | Loss: 0.5534 | 1.4 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 34/320 (57/57) | Loss: 0.5462 | 1.4 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 35/320 (57/57) | Loss: 0.5314 | 1.3 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 36/320 (57/57) | Loss: 0.5249 | 1.3 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 37/320 (57/57) | Loss: 0.5300 | 1.3 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 38/320 (57/57) | Loss: 0.5275 | 1.4 steps/s | Step: 3k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 39/320 (34/57) | Loss: 0.5190 | 1.4 steps/s | Step: 4k | }Input at step 4000: it forces you to go rework your model~___________________________________________________\n",
            "{| Epoch: 39/320 (57/57) | Loss: 0.5209 | 1.4 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 40/320 (57/57) | Loss: 0.5082 | 1.3 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 41/320 (57/57) | Loss: 0.5050 | 1.4 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 42/320 (57/57) | Loss: 0.4968 | 1.4 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 43/320 (57/57) | Loss: 0.4963 | 1.3 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 44/320 (57/57) | Loss: 0.4931 | 1.3 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 45/320 (57/57) | Loss: 0.4877 | 1.4 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 46/320 (57/57) | Loss: 0.4870 | 1.3 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 47/320 (57/57) | Loss: 0.4883 | 1.3 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 48/320 (21/57) | Loss: 0.4855 | 1.3 steps/s | Step: 4k | }Input at step 4500: but the issue is getting a space here~_______________________________\n",
            "{| Epoch: 48/320 (57/57) | Loss: 0.4917 | 1.4 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 49/320 (57/57) | Loss: 0.4808 | 1.4 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 50/320 (57/57) | Loss: 0.4730 | 1.3 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 51/320 (57/57) | Loss: 0.4735 | 1.3 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 52/320 (57/57) | Loss: 0.4698 | 1.3 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 53/320 (57/57) | Loss: 0.4638 | 1.3 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 54/320 (57/57) | Loss: 0.4529 | 1.3 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 55/320 (57/57) | Loss: 0.4528 | 1.4 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 56/320 (57/57) | Loss: 0.4544 | 1.4 steps/s | Step: 4k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 57/320 (8/57) | Loss: 0.4506 | 1.4 steps/s | Step: 5k | }Input at step 5000: there must be impact so i see this~_________________________________\n",
            "{| Epoch: 57/320 (57/57) | Loss: 0.4475 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 58/320 (57/57) | Loss: 0.4355 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 59/320 (57/57) | Loss: 0.4327 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 60/320 (57/57) | Loss: 0.4364 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 61/320 (57/57) | Loss: 0.4317 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 62/320 (57/57) | Loss: 0.4266 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 63/320 (57/57) | Loss: 0.4233 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 64/320 (57/57) | Loss: 0.4292 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 65/320 (52/57) | Loss: 0.4293 | 1.3 steps/s | Step: 5k | }Input at step 5500: we to have present what we do we ran~__________________________________\n",
            "{| Epoch: 65/320 (57/57) | Loss: 0.4311 | 1.4 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 66/320 (57/57) | Loss: 0.4216 | 1.4 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 67/320 (57/57) | Loss: 0.4142 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 68/320 (57/57) | Loss: 0.4161 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 69/320 (57/57) | Loss: 0.4070 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 70/320 (57/57) | Loss: 0.4064 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 71/320 (57/57) | Loss: 0.4092 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 72/320 (57/57) | Loss: 0.4032 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 73/320 (57/57) | Loss: 0.3973 | 1.3 steps/s | Step: 5k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 74/320 (39/57) | Loss: 0.3874 | 1.3 steps/s | Step: 6k | }Input at step 6000: while also enhancing~_______________________________________________________________________________\n",
            "{| Epoch: 74/320 (57/57) | Loss: 0.3873 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 75/320 (57/57) | Loss: 0.3920 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 76/320 (57/57) | Loss: 0.3981 | 1.4 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 77/320 (57/57) | Loss: 0.3921 | 1.4 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 78/320 (57/57) | Loss: 0.3880 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 79/320 (57/57) | Loss: 0.3865 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 80/320 (57/57) | Loss: 0.3798 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 81/320 (57/57) | Loss: 0.3807 | 1.4 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 82/320 (57/57) | Loss: 0.3845 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 83/320 (26/57) | Loss: 0.3856 | 1.3 steps/s | Step: 6k | }Input at step 6500: i said erm~___________________________________________________________________________________________________________\n",
            "{| Epoch: 83/320 (57/57) | Loss: 0.3833 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 84/320 (57/57) | Loss: 0.3783 | 1.4 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 85/320 (57/57) | Loss: 0.3681 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 86/320 (57/57) | Loss: 0.3659 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 87/320 (57/57) | Loss: 0.3598 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 88/320 (57/57) | Loss: 0.3588 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 89/320 (57/57) | Loss: 0.3560 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 90/320 (57/57) | Loss: 0.3594 | 1.3 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 91/320 (57/57) | Loss: 0.3611 | 1.4 steps/s | Step: 6k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 92/320 (13/57) | Loss: 0.3594 | 1.3 steps/s | Step: 7k | }Input at step 7000: ah just last week there was i c l r~____________________________________________\n",
            "{| Epoch: 92/320 (57/57) | Loss: 0.3605 | 1.3 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 93/320 (57/57) | Loss: 0.3621 | 1.3 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 94/320 (57/57) | Loss: 0.3611 | 1.4 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 95/320 (57/57) | Loss: 0.3552 | 1.3 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 96/320 (57/57) | Loss: 0.3499 | 1.3 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 97/320 (57/57) | Loss: 0.3473 | 1.3 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 98/320 (57/57) | Loss: 0.3485 | 1.3 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 99/320 (57/57) | Loss: 0.3488 | 1.3 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 100/320 (57/57) | Loss: 0.3495 | 1.3 steps/s | Step: 7k | }Input at step 7500: terms of approach we have deployed based ah face to face~__________________________\n",
            "\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 101/320 (57/57) | Loss: 0.3416 | 1.4 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 102/320 (57/57) | Loss: 0.3377 | 1.3 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 103/320 (57/57) | Loss: 0.3406 | 1.3 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 104/320 (57/57) | Loss: 0.3445 | 1.4 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 105/320 (57/57) | Loss: 0.3391 | 1.3 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 106/320 (57/57) | Loss: 0.3396 | 1.3 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 107/320 (57/57) | Loss: 0.3423 | 1.4 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 108/320 (57/57) | Loss: 0.3380 | 1.4 steps/s | Step: 7k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 109/320 (44/57) | Loss: 0.3354 | 1.3 steps/s | Step: 8k | }Input at step 8000: and one area that~_____________________________________\n",
            "{| Epoch: 109/320 (57/57) | Loss: 0.3353 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 110/320 (57/57) | Loss: 0.3306 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 111/320 (57/57) | Loss: 0.3301 | 1.4 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 112/320 (57/57) | Loss: 0.3299 | 1.4 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 113/320 (57/57) | Loss: 0.3321 | 1.4 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 114/320 (57/57) | Loss: 0.3308 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 115/320 (57/57) | Loss: 0.3224 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 116/320 (57/57) | Loss: 0.3231 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 117/320 (57/57) | Loss: 0.3264 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 118/320 (31/57) | Loss: 0.3243 | 1.3 steps/s | Step: 8k | }Input at step 8500: coach and that is the kind of quality of many other ones are from harvard~\n",
            "{| Epoch: 118/320 (57/57) | Loss: 0.3273 | 1.4 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 119/320 (57/57) | Loss: 0.3129 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 120/320 (57/57) | Loss: 0.3101 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 121/320 (57/57) | Loss: 0.3126 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 122/320 (57/57) | Loss: 0.3130 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 123/320 (57/57) | Loss: 0.3146 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 124/320 (57/57) | Loss: 0.3152 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 125/320 (57/57) | Loss: 0.3175 | 1.4 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 126/320 (57/57) | Loss: 0.3330 | 1.3 steps/s | Step: 8k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 127/320 (18/57) | Loss: 0.3354 | 1.3 steps/s | Step: 9k | }Input at step 9000: this video has seen about twenty thousand views i think it is worth~__________________________________________________\n",
            "{| Epoch: 127/320 (57/57) | Loss: 0.3245 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 128/320 (57/57) | Loss: 0.3084 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 129/320 (57/57) | Loss: 0.3115 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 130/320 (57/57) | Loss: 0.3079 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 131/320 (57/57) | Loss: 0.3286 | 1.4 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 132/320 (57/57) | Loss: 0.3319 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 133/320 (57/57) | Loss: 0.3179 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 134/320 (57/57) | Loss: 0.3099 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 135/320 (57/57) | Loss: 0.3024 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 136/320 (5/57) | Loss: 0.3037 | 1.3 steps/s | Step: 9k | }Input at step 9500: and can now count the~_______________________________________\n",
            "{| Epoch: 136/320 (57/57) | Loss: 0.3045 | 1.4 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 137/320 (57/57) | Loss: 0.2974 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 138/320 (57/57) | Loss: 0.2946 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 139/320 (57/57) | Loss: 0.3005 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 140/320 (57/57) | Loss: 0.2987 | 1.4 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 141/320 (57/57) | Loss: 0.2956 | 1.4 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 142/320 (57/57) | Loss: 0.2926 | 1.3 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 143/320 (57/57) | Loss: 0.2911 | 1.4 steps/s | Step: 9k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 144/320 (49/57) | Loss: 0.2910 | 1.4 steps/s | Step: 10k | }Input at step 10000: can be applied in optimising classroom management~______\n",
            "{| Epoch: 144/320 (57/57) | Loss: 0.2919 | 1.4 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 145/320 (57/57) | Loss: 0.2911 | 1.3 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 146/320 (57/57) | Loss: 0.2969 | 1.4 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 147/320 (57/57) | Loss: 0.3161 | 1.4 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 148/320 (57/57) | Loss: 0.3214 | 1.3 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 149/320 (57/57) | Loss: 0.3028 | 1.3 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 150/320 (57/57) | Loss: 0.2933 | 1.3 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 151/320 (57/57) | Loss: 0.2919 | 1.4 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 152/320 (57/57) | Loss: 0.2873 | 1.3 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 153/320 (36/57) | Loss: 0.2811 | 1.3 steps/s | Step: 10k | }Input at step 10500: as general manager business intelligence~_____________________________\n",
            "{| Epoch: 153/320 (57/57) | Loss: 0.2833 | 1.3 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 154/320 (57/57) | Loss: 0.2856 | 1.4 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 155/320 (57/57) | Loss: 0.2802 | 1.3 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 156/320 (57/57) | Loss: 0.2782 | 1.3 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 157/320 (57/57) | Loss: 0.2836 | 1.4 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 158/320 (57/57) | Loss: 0.2844 | 1.4 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 159/320 (57/57) | Loss: 0.2833 | 1.3 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 160/320 (57/57) | Loss: 0.2800 | 1.3 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 161/320 (57/57) | Loss: 0.2769 | 1.3 steps/s | Step: 10k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 162/320 (23/57) | Loss: 0.2767 | 1.3 steps/s | Step: 11k | }Input at step 11000: to learn the mo~____________________________________________\n",
            "{| Epoch: 162/320 (57/57) | Loss: 0.2790 | 1.3 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 163/320 (57/57) | Loss: 0.2797 | 1.3 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 164/320 (57/57) | Loss: 0.2810 | 1.4 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 165/320 (57/57) | Loss: 0.2820 | 1.4 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 166/320 (57/57) | Loss: 0.2767 | 1.3 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 167/320 (57/57) | Loss: 0.2751 | 1.3 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 168/320 (57/57) | Loss: 0.2723 | 1.4 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 169/320 (57/57) | Loss: 0.2728 | 1.3 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 170/320 (57/57) | Loss: 0.2738 | 1.3 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 171/320 (10/57) | Loss: 0.2719 | 1.3 steps/s | Step: 11k | }Input at step 11500: track your brand aware you know visibility~_______________\n",
            "{| Epoch: 171/320 (57/57) | Loss: 0.2733 | 1.4 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 172/320 (57/57) | Loss: 0.2727 | 1.4 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 173/320 (57/57) | Loss: 0.2717 | 1.3 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 174/320 (57/57) | Loss: 0.2754 | 1.4 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 175/320 (57/57) | Loss: 0.2712 | 1.4 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 176/320 (57/57) | Loss: 0.2668 | 1.3 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 177/320 (57/57) | Loss: 0.2679 | 1.3 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 178/320 (57/57) | Loss: 0.2646 | 1.3 steps/s | Step: 11k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 179/320 (54/57) | Loss: 0.2685 | 1.3 steps/s | Step: 12k | }Input at step 12000: how did they do it you can ask questions~___________________________________________________________________________\n",
            "{| Epoch: 179/320 (57/57) | Loss: 0.2684 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 180/320 (57/57) | Loss: 0.2699 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 181/320 (57/57) | Loss: 0.2670 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 182/320 (57/57) | Loss: 0.2672 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 183/320 (57/57) | Loss: 0.2716 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 184/320 (57/57) | Loss: 0.2689 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 185/320 (57/57) | Loss: 0.2661 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 186/320 (57/57) | Loss: 0.2668 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 187/320 (57/57) | Loss: 0.2658 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 188/320 (41/57) | Loss: 0.2673 | 1.3 steps/s | Step: 12k | }Input at step 12500: know you remember i've established it to~___________________________\n",
            "{| Epoch: 188/320 (57/57) | Loss: 0.2671 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 189/320 (57/57) | Loss: 0.2635 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 190/320 (57/57) | Loss: 0.2624 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 191/320 (57/57) | Loss: 0.2610 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 192/320 (57/57) | Loss: 0.2605 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 193/320 (57/57) | Loss: 0.2597 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 194/320 (57/57) | Loss: 0.2542 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 195/320 (57/57) | Loss: 0.2558 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 196/320 (57/57) | Loss: 0.2602 | 1.3 steps/s | Step: 12k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 197/320 (28/57) | Loss: 0.2586 | 1.3 steps/s | Step: 13k | }Input at step 13000: stimulate your interest to build capacity in ai~__________________________\n",
            "{| Epoch: 197/320 (57/57) | Loss: 0.2569 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 198/320 (57/57) | Loss: 0.2571 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 199/320 (57/57) | Loss: 0.2549 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 200/320 (57/57) | Loss: 0.2537 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 201/320 (57/57) | Loss: 0.2523 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 202/320 (57/57) | Loss: 0.2551 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 203/320 (57/57) | Loss: 0.2576 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 204/320 (57/57) | Loss: 0.2585 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 205/320 (57/57) | Loss: 0.2570 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 206/320 (15/57) | Loss: 0.2533 | 1.3 steps/s | Step: 13k | }Input at step 13500: availabe the work we have done is to painstakingly~__________________\n",
            "{| Epoch: 206/320 (57/57) | Loss: 0.2571 | 1.4 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 207/320 (57/57) | Loss: 0.2575 | 1.4 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 208/320 (57/57) | Loss: 0.2557 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 209/320 (57/57) | Loss: 0.2612 | 1.4 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 210/320 (57/57) | Loss: 0.2573 | 1.4 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 211/320 (57/57) | Loss: 0.2520 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 212/320 (57/57) | Loss: 0.2517 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 213/320 (57/57) | Loss: 0.2571 | 1.4 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 214/320 (57/57) | Loss: 0.2560 | 1.3 steps/s | Step: 13k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 215/320 (2/57) | Loss: 0.2566 | 1.3 steps/s | Step: 14k | }Input at step 14000: that student are receiving~_______________________________________________________\n",
            "{| Epoch: 215/320 (57/57) | Loss: 0.2534 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 216/320 (57/57) | Loss: 0.2510 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 217/320 (57/57) | Loss: 0.2487 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 218/320 (57/57) | Loss: 0.2519 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 219/320 (57/57) | Loss: 0.2531 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 220/320 (57/57) | Loss: 0.2531 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 221/320 (57/57) | Loss: 0.2503 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 222/320 (57/57) | Loss: 0.2473 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 223/320 (46/57) | Loss: 0.2474 | 1.3 steps/s | Step: 14k | }Input at step 14500: summere school where we train them in python~______________\n",
            "{| Epoch: 223/320 (57/57) | Loss: 0.2495 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 224/320 (57/57) | Loss: 0.2511 | 1.4 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 225/320 (57/57) | Loss: 0.2454 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 226/320 (57/57) | Loss: 0.2443 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 227/320 (57/57) | Loss: 0.2441 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 228/320 (57/57) | Loss: 0.2434 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 229/320 (57/57) | Loss: 0.2414 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 230/320 (57/57) | Loss: 0.2426 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 231/320 (57/57) | Loss: 0.2405 | 1.3 steps/s | Step: 14k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 232/320 (33/57) | Loss: 0.2421 | 1.3 steps/s | Step: 15k | }Input at step 15000: and we can have this kind of dashboard where~_______________________\n",
            "{| Epoch: 232/320 (57/57) | Loss: 0.2433 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 233/320 (57/57) | Loss: 0.2459 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 234/320 (57/57) | Loss: 0.2453 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 235/320 (57/57) | Loss: 0.2468 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 236/320 (57/57) | Loss: 0.2447 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 237/320 (57/57) | Loss: 0.2440 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 238/320 (57/57) | Loss: 0.2450 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 239/320 (57/57) | Loss: 0.2492 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 240/320 (57/57) | Loss: 0.2460 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 241/320 (20/57) | Loss: 0.2457 | 1.3 steps/s | Step: 15k | }Input at step 15500: on project that are in~___________________________________________________________\n",
            "{| Epoch: 241/320 (57/57) | Loss: 0.2392 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 242/320 (57/57) | Loss: 0.2396 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 243/320 (57/57) | Loss: 0.2413 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 244/320 (57/57) | Loss: 0.2362 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 245/320 (57/57) | Loss: 0.2390 | 1.4 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 246/320 (57/57) | Loss: 0.2354 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 247/320 (57/57) | Loss: 0.2360 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 248/320 (57/57) | Loss: 0.2364 | 1.4 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 249/320 (57/57) | Loss: 0.2346 | 1.3 steps/s | Step: 15k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 250/320 (7/57) | Loss: 0.2358 | 1.3 steps/s | Step: 16k | }Input at step 16000: you remember we are not about job~______________________________\n",
            "{| Epoch: 250/320 (57/57) | Loss: 0.2349 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 251/320 (57/57) | Loss: 0.2316 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 252/320 (57/57) | Loss: 0.2358 | 1.4 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 253/320 (57/57) | Loss: 0.2372 | 1.4 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 254/320 (57/57) | Loss: 0.2382 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 255/320 (57/57) | Loss: 0.2384 | 1.4 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 256/320 (57/57) | Loss: 0.2363 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 257/320 (57/57) | Loss: 0.2402 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 258/320 (51/57) | Loss: 0.2414 | 1.3 steps/s | Step: 16k | }Input at step 16500: place in kenya~_____________________________________________________\n",
            "{| Epoch: 258/320 (57/57) | Loss: 0.2422 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 259/320 (57/57) | Loss: 0.2385 | 1.4 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 260/320 (57/57) | Loss: 0.2381 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 261/320 (57/57) | Loss: 0.2418 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 262/320 (57/57) | Loss: 0.2405 | 1.4 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 263/320 (57/57) | Loss: 0.2333 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 264/320 (57/57) | Loss: 0.2285 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 265/320 (57/57) | Loss: 0.2479 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 266/320 (57/57) | Loss: 0.3518 | 1.3 steps/s | Step: 16k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 267/320 (38/57) | Loss: 0.4266 | 1.3 steps/s | Step: 17k | }Input at step 17000: ah that is being done in data science nigeria~_____________________________________________________________\n",
            "{| Epoch: 267/320 (57/57) | Loss: 0.4292 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 268/320 (57/57) | Loss: 0.3727 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 269/320 (57/57) | Loss: 0.3064 | 1.4 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 270/320 (57/57) | Loss: 0.2729 | 1.4 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 271/320 (57/57) | Loss: 0.2546 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 272/320 (57/57) | Loss: 0.2415 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 273/320 (57/57) | Loss: 0.2400 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 274/320 (57/57) | Loss: 0.2346 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 275/320 (57/57) | Loss: 0.2307 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 276/320 (25/57) | Loss: 0.2312 | 1.3 steps/s | Step: 17k | }Input at step 17500: do this task we gave over one million megabytes of data~__________________________________________\n",
            "{| Epoch: 276/320 (57/57) | Loss: 0.2289 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 277/320 (57/57) | Loss: 0.2285 | 1.4 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 278/320 (57/57) | Loss: 0.2258 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 279/320 (57/57) | Loss: 0.2257 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 280/320 (57/57) | Loss: 0.2228 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 281/320 (57/57) | Loss: 0.2216 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 282/320 (57/57) | Loss: 0.2230 | 1.3 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 283/320 (57/57) | Loss: 0.2238 | 1.4 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 284/320 (57/57) | Loss: 0.2229 | 1.4 steps/s | Step: 17k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 285/320 (12/57) | Loss: 0.2228 | 1.4 steps/s | Step: 18k | }Input at step 18000: conferences~____________________________________________________________\n",
            "{| Epoch: 285/320 (57/57) | Loss: 0.2212 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 286/320 (57/57) | Loss: 0.2230 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 287/320 (57/57) | Loss: 0.2230 | 1.4 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 288/320 (57/57) | Loss: 0.2230 | 1.4 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 289/320 (57/57) | Loss: 0.2192 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 290/320 (57/57) | Loss: 0.2193 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 291/320 (57/57) | Loss: 0.2207 | 1.4 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 292/320 (57/57) | Loss: 0.2181 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 293/320 (56/57) | Loss: 0.2174 | 1.3 steps/s | Step: 18k | }Input at step 18500: five gig some got two gig depending on~_______________________________________\n",
            "{| Epoch: 293/320 (57/57) | Loss: 0.2172 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 294/320 (57/57) | Loss: 0.2216 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 295/320 (57/57) | Loss: 0.2228 | 1.4 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 296/320 (57/57) | Loss: 0.2236 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 297/320 (57/57) | Loss: 0.2195 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 298/320 (57/57) | Loss: 0.2207 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 299/320 (57/57) | Loss: 0.2219 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 300/320 (57/57) | Loss: 0.2225 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 301/320 (57/57) | Loss: 0.2217 | 1.3 steps/s | Step: 18k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 302/320 (43/57) | Loss: 0.2226 | 1.3 steps/s | Step: 19k | }Input at step 19000: is sorted and of course this is because~_____________________\n",
            "{| Epoch: 302/320 (57/57) | Loss: 0.2218 | 1.3 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 303/320 (57/57) | Loss: 0.2228 | 1.3 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 304/320 (57/57) | Loss: 0.2211 | 1.3 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 305/320 (57/57) | Loss: 0.2183 | 1.3 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 306/320 (57/57) | Loss: 0.2174 | 1.3 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 307/320 (57/57) | Loss: 0.2272 | 1.3 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 308/320 (57/57) | Loss: 0.2289 | 1.4 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 309/320 (57/57) | Loss: 0.2274 | 1.4 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 310/320 (57/57) | Loss: 0.2281 | 1.3 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 311/320 (30/57) | Loss: 0.2295 | 1.3 steps/s | Step: 19k | }Input at step 19500: and then we put in a usb exatly~____________________________________\n",
            "{| Epoch: 311/320 (57/57) | Loss: 0.2268 | 1.4 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 312/320 (57/57) | Loss: 0.2258 | 1.4 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 313/320 (57/57) | Loss: 0.2264 | 1.3 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 314/320 (57/57) | Loss: 0.2265 | 1.3 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 315/320 (57/57) | Loss: 0.2315 | 1.4 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 316/320 (57/57) | Loss: 0.2304 | 1.4 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 317/320 (57/57) | Loss: 0.2259 | 1.3 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 318/320 (57/57) | Loss: 0.2233 | 1.4 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 319/320 (57/57) | Loss: 0.2206 | 1.3 steps/s | Step: 19k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 320/320 (17/57) | Loss: 0.2184 | 1.3 steps/s | Step: 20k | }Input at step 20000: eh epidemiological modelling committees~__________________________________________________________\n",
            "\n",
            "+----------------+------------+---------------+------------------+\n",
            "| Steps with r=2 | Batch Size | Learning Rate | Outputs/Step (r) |\n",
            "+----------------+------------+---------------+------------------+\n",
            "|   20k Steps    |     12     |    0.0005     |        2         |\n",
            "+----------------+------------+---------------+------------------+\n",
            " \n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 1/351 (57/57) | Loss: 0.2156 | 1.4 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 2/351 (57/57) | Loss: 0.2065 | 1.4 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 3/351 (57/57) | Loss: 0.1982 | 1.3 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 4/351 (57/57) | Loss: 0.1980 | 1.3 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 5/351 (57/57) | Loss: 0.1981 | 1.4 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 6/351 (57/57) | Loss: 0.1981 | 1.4 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 7/351 (57/57) | Loss: 0.1946 | 1.4 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 8/351 (57/57) | Loss: 0.1923 | 1.3 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 9/351 (44/57) | Loss: 0.1916 | 1.3 steps/s | Step: 20k | }Input at step 20500: by their engagement level on this axis~____________________________\n",
            "{| Epoch: 9/351 (57/57) | Loss: 0.1936 | 1.3 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 10/351 (57/57) | Loss: 0.1945 | 1.4 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 11/351 (57/57) | Loss: 0.1928 | 1.3 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 12/351 (57/57) | Loss: 0.1942 | 1.3 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 13/351 (57/57) | Loss: 0.1975 | 1.4 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 14/351 (57/57) | Loss: 0.1962 | 1.4 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 15/351 (57/57) | Loss: 0.1932 | 1.3 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 16/351 (57/57) | Loss: 0.1932 | 1.3 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 17/351 (57/57) | Loss: 0.1946 | 1.4 steps/s | Step: 20k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 18/351 (31/57) | Loss: 0.1921 | 1.3 steps/s | Step: 21k | }Input at step 21000: did data science one o one this is a kind of video~__________________\n",
            "{| Epoch: 18/351 (57/57) | Loss: 0.1910 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 19/351 (57/57) | Loss: 0.1945 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 20/351 (57/57) | Loss: 0.1935 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 21/351 (57/57) | Loss: 0.1919 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 22/351 (57/57) | Loss: 0.1925 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 23/351 (57/57) | Loss: 0.1926 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 24/351 (57/57) | Loss: 0.1951 | 1.4 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 25/351 (57/57) | Loss: 0.1918 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 26/351 (57/57) | Loss: 0.1939 | 1.4 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 27/351 (18/57) | Loss: 0.1943 | 1.4 steps/s | Step: 21k | }Input at step 21500: ah when we started this conversation on you can etymology of career~____________________________________________\n",
            "{| Epoch: 27/351 (57/57) | Loss: 0.1953 | 1.4 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 28/351 (57/57) | Loss: 0.1929 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 29/351 (57/57) | Loss: 0.1920 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 30/351 (57/57) | Loss: 0.1929 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 31/351 (57/57) | Loss: 0.1914 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 32/351 (57/57) | Loss: 0.1930 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 33/351 (57/57) | Loss: 0.1922 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 34/351 (57/57) | Loss: 0.1900 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 35/351 (57/57) | Loss: 0.1898 | 1.3 steps/s | Step: 21k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 36/351 (5/57) | Loss: 0.1885 | 1.3 steps/s | Step: 22k | }Input at step 22000: make observation take picture~______________________________________________\n",
            "{| Epoch: 36/351 (57/57) | Loss: 0.1903 | 1.4 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 37/351 (57/57) | Loss: 0.1918 | 1.3 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 38/351 (57/57) | Loss: 0.1922 | 1.4 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 39/351 (57/57) | Loss: 0.1927 | 1.4 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 40/351 (57/57) | Loss: 0.1881 | 1.3 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 41/351 (57/57) | Loss: 0.1896 | 1.3 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 42/351 (57/57) | Loss: 0.1894 | 1.3 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 43/351 (57/57) | Loss: 0.1905 | 1.3 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 44/351 (49/57) | Loss: 0.1904 | 1.4 steps/s | Step: 22k | }Input at step 22500: experts who also contributed to this~______________________________________________\n",
            "{| Epoch: 44/351 (57/57) | Loss: 0.1912 | 1.4 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 45/351 (57/57) | Loss: 0.1910 | 1.3 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 46/351 (57/57) | Loss: 0.1880 | 1.3 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 47/351 (57/57) | Loss: 0.1864 | 1.3 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 48/351 (57/57) | Loss: 0.1915 | 1.3 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 49/351 (57/57) | Loss: 0.1920 | 1.3 steps/s | Step: 22k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 50/351 (46/57) | Loss: 0.1928 | 1.4 steps/s | Step: 22k | }Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb30c539dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1282, in _shutdown_workers\n",
            "    self._worker_result_queue.put((None, None))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 87, in put\n",
            "    self._start_thread()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 170, in _start_thread\n",
            "    self._thread.start()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 857, in start\n",
            "    self._started.wait()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 552, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 296, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"synthesizer_train.py\", line 35, in <module>\n",
            "    train(**vars(args))\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/train.py\", line 178, in train\n",
            "    m1_hat, m2_hat, attention, stop_pred = model(texts, mels, embeds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/models/tacotron.py\", line 397, in forward\n",
            "    hidden_states, cell_states, context_vec, t, x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/models/tacotron.py\", line 316, in forward\n",
            "    mels = mels.view(batch_size, self.n_mels, self.max_r)[:, :, :self.r]\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python synthesizer_train.py pretrained synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer -s 200 -b 100 #--checkpoint_interval 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLrODsZgq43K",
        "outputId": "e830469b-8c1a-4665-f50a-e97986986151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1ghVyGRp2cYU_DXL7LpZyb8lTHCHmunMU/Voice Cloning/Real-Time-Voice-Cloning\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "gNeAtlTn8Vkw",
        "outputId": "1780ce8e-92b4-44e4-bb9d-6eec096426c1"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-b8c0cdfa518b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1163k checkpoint changed to pretrained\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# 1163k checkpoint changed to pretrained\n",
        "# 320k pretrained synthesizer chained to pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viM1frTSlMPF",
        "outputId": "b7291bbf-199d-4486-ce20-4f24d0fc9b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    datasets_root:   /content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root\n",
            "    model_dir:       /content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/pretrained\n",
            "    in_dir:          ./synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer\n",
            "    out_dir:         ./synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/vocoder\n",
            "    hparams:         \n",
            "    no_trim:         False\n",
            "    cpu:             False\n",
            "\n",
            "{'allow_clipping_in_normalization': True,\n",
            " 'clip_mels_length': True,\n",
            " 'fmax': 7600,\n",
            " 'fmin': 55,\n",
            " 'griffin_lim_iters': 60,\n",
            " 'hop_size': 200,\n",
            " 'max_abs_value': 4.0,\n",
            " 'max_mel_frames': 900,\n",
            " 'min_level_db': -100,\n",
            " 'n_fft': 800,\n",
            " 'num_mels': 80,\n",
            " 'power': 1.5,\n",
            " 'preemphasis': 0.97,\n",
            " 'preemphasize': True,\n",
            " 'ref_level_db': 20,\n",
            " 'rescale': True,\n",
            " 'rescaling_max': 0.9,\n",
            " 'sample_rate': 16000,\n",
            " 'signal_normalization': True,\n",
            " 'silence_min_duration_split': 0.2,\n",
            " 'speaker_embedding_size': 256,\n",
            " 'symmetric_mels': True,\n",
            " 'synthesis_batch_size': 16,\n",
            " 'trim_silence': True,\n",
            " 'tts_cleaner_names': ['english_cleaners'],\n",
            " 'tts_clip_grad_norm': 1.0,\n",
            " 'tts_decoder_dims': 128,\n",
            " 'tts_dropout': 0.5,\n",
            " 'tts_embed_dims': 512,\n",
            " 'tts_encoder_K': 5,\n",
            " 'tts_encoder_dims': 256,\n",
            " 'tts_eval_interval': 500,\n",
            " 'tts_eval_num_samples': 1,\n",
            " 'tts_lstm_dims': 1024,\n",
            " 'tts_num_highways': 4,\n",
            " 'tts_postnet_K': 5,\n",
            " 'tts_postnet_dims': 512,\n",
            " 'tts_schedule': [(2, 0.001, 20000, 12),\n",
            "                  (2, 0.0005, 40000, 12),\n",
            "                  (2, 0.0002, 80000, 12),\n",
            "                  (2, 0.0001, 160000, 12),\n",
            "                  (2, 3e-05, 320000, 12),\n",
            "                  (2, 1e-05, 640000, 12)],\n",
            " 'tts_stop_threshold': -3.4,\n",
            " 'use_lws': False,\n",
            " 'utterance_min_duration': 1.0,\n",
            " 'win_size': 800}\n",
            "Synthesizer using device: cuda\n",
            "Trainable Parameters: 30.870M\n",
            "\n",
            "Loading weights at /content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/pretrained/pretrained.pt\n",
            "Tacotron weights loaded from step 320900\n",
            "Using inputs from:\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/train.txt\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/mels\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/embeds\n",
            "Found 684 samples\n",
            "  0% 0/43 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "100% 43/43 [04:13<00:00,  5.90s/it]\n"
          ]
        }
      ],
      "source": [
        "!python vocoder_preprocess.py -i \"./synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer\" -o \"./synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/vocoder\" --model_dir \"/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/pretrained\"  \"/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh1Iyxj0wHec"
      },
      "outputs": [],
      "source": [
        "pretrained_300k was renamed to pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZpdn4Pzr3IL"
      },
      "outputs": [],
      "source": [
        "same as checkpoint_1161k_steps\n",
        "same as checkpoint_1165k_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jcDBZwIyuO8",
        "outputId": "24ab6ce0-de42-4e46-a541-86fc29b0da7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    run_id:          pretrained\n",
            "    syn_dir:         synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer\n",
            "    voc_dir:         synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/vocoder\n",
            "    models_dir:      vocoder/saved_models\n",
            "    ground_truth:    False\n",
            "    save_every:      100\n",
            "    backup_every:    250\n",
            "    force_restart:   False\n",
            "\n",
            "Initializing the model...\n",
            "Trainable Parameters: 4.481M\n",
            "\n",
            "Loading weights at vocoder/saved_models/pretrained/pretrained.pt\n",
            "WaveRNN weights loaded from step 1170250\n",
            "Using inputs from:\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/vocoder/synthesized.txt\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/vocoder/mels_gta\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/audio\n",
            "Found 684 samples\n",
            "+------------+--------+--------------+\n",
            "| Batch size |   LR   | Sequence Len |\n",
            "+------------+--------+--------------+\n",
            "|    100     | 0.0001 |     1000     |\n",
            "+------------+--------+--------------+\n",
            " \n",
            "{| Epoch: 1 (7/7) | Loss: 3.4911 | 0.0 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 2 (7/7) | Loss: 3.5148 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 78300/79200 | Batch Size: 9 | Gen Rate: 14.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 3 (7/7) | Loss: 3.4936 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 4 (7/7) | Loss: 3.5025 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 78300/79200 | Batch Size: 9 | Gen Rate: 14.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 5 (7/7) | Loss: 3.5111 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 6 (7/7) | Loss: 3.4531 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 7 (7/7) | Loss: 3.4850 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 8 (7/7) | Loss: 3.4653 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 9 (7/7) | Loss: 3.4285 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 10 (7/7) | Loss: 3.4869 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 11 (7/7) | Loss: 3.4744 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 11.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 12 (7/7) | Loss: 3.5018 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 13 (7/7) | Loss: 3.5005 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 14 (7/7) | Loss: 3.4683 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 15 (7/7) | Loss: 3.5237 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 16 (7/7) | Loss: 3.4668 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 17 (7/7) | Loss: 3.4738 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 18 (7/7) | Loss: 3.4809 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 19 (7/7) | Loss: 3.5217 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 20 (7/7) | Loss: 3.4525 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 95700/96800 | Batch Size: 11 | Gen Rate: 17.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 21 (7/7) | Loss: 3.4702 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 22 (7/7) | Loss: 3.5160 | 1.2 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 23 (7/7) | Loss: 3.4619 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 24 (7/7) | Loss: 3.5035 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 25 (7/7) | Loss: 3.4734 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 26 (7/7) | Loss: 3.4903 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 11.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 27 (7/7) | Loss: 3.5382 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 28 (7/7) | Loss: 3.4852 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 29 (7/7) | Loss: 3.5155 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 30 (7/7) | Loss: 3.4861 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 31 (7/7) | Loss: 3.4831 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 32 (7/7) | Loss: 3.4567 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 95700/96800 | Batch Size: 11 | Gen Rate: 17.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 33 (7/7) | Loss: 3.5083 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 34 (7/7) | Loss: 3.4660 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 35 (7/7) | Loss: 3.5258 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 11.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 36 (7/7) | Loss: 3.4594 | 1.1 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 37 (7/7) | Loss: 3.4688 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 38 (7/7) | Loss: 3.4892 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 39 (7/7) | Loss: 3.5131 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 40 (7/7) | Loss: 3.4890 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 104400/105600 | Batch Size: 12 | Gen Rate: 18.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 41 (7/7) | Loss: 3.5251 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 42 (7/7) | Loss: 3.5004 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 43 (7/7) | Loss: 3.4706 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 44 (7/7) | Loss: 3.5200 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 45 (7/7) | Loss: 3.5460 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 46 (7/7) | Loss: 3.4631 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 47 (7/7) | Loss: 3.5019 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 48 (7/7) | Loss: 3.4773 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 49 (7/7) | Loss: 3.4786 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 50 (7/7) | Loss: 3.5065 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 51 (7/7) | Loss: 3.5011 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 52 (7/7) | Loss: 3.4346 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 53 (7/7) | Loss: 3.4777 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 54 (7/7) | Loss: 3.4691 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 55 (7/7) | Loss: 3.5036 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 56 (7/7) | Loss: 3.4730 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 57 (7/7) | Loss: 3.4948 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 58 (7/7) | Loss: 3.5059 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 59 (7/7) | Loss: 3.4595 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 17400/17600 | Batch Size: 2 | Gen Rate: 3.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 60 (7/7) | Loss: 3.4848 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 61 (7/7) | Loss: 3.4745 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 78300/79200 | Batch Size: 9 | Gen Rate: 13.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 62 (7/7) | Loss: 3.4930 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 11.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 63 (7/7) | Loss: 3.4750 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 64 (7/7) | Loss: 3.4743 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 65 (7/7) | Loss: 3.4601 | 1.2 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 66 (7/7) | Loss: 3.5167 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 67 (7/7) | Loss: 3.4494 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 68 (7/7) | Loss: 3.5317 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 69 (7/7) | Loss: 3.4719 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 70 (7/7) | Loss: 3.4848 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 11.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 71 (7/7) | Loss: 3.4677 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 72 (7/7) | Loss: 3.5125 | 1.2 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 73 (7/7) | Loss: 3.4954 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 74 (7/7) | Loss: 3.4704 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 75 (7/7) | Loss: 3.5049 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 76 (7/7) | Loss: 3.4900 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 77 (7/7) | Loss: 3.4836 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 78 (7/7) | Loss: 3.4912 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 79 (7/7) | Loss: 3.4495 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 80 (7/7) | Loss: 3.4801 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 81 (7/7) | Loss: 3.4149 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 82 (7/7) | Loss: 3.4544 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 83 (7/7) | Loss: 3.5164 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 84 (7/7) | Loss: 3.4616 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 85 (7/7) | Loss: 3.4992 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 86 (7/7) | Loss: 3.4751 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 87 (7/7) | Loss: 3.4886 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 88 (7/7) | Loss: 3.4172 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 89 (7/7) | Loss: 3.4393 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 17400/17600 | Batch Size: 2 | Gen Rate: 3.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 90 (7/7) | Loss: 3.5145 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 91 (7/7) | Loss: 3.4822 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 17400/17600 | Batch Size: 2 | Gen Rate: 3.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 92 (7/7) | Loss: 3.4837 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 93 (7/7) | Loss: 3.4730 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 94 (7/7) | Loss: 3.5085 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 95 (7/7) | Loss: 3.5058 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 96 (7/7) | Loss: 3.4756 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 97 (7/7) | Loss: 3.4601 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 98 (7/7) | Loss: 3.5034 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 99 (7/7) | Loss: 3.4911 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 100 (7/7) | Loss: 3.4816 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 101 (7/7) | Loss: 3.4707 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 102 (7/7) | Loss: 3.5229 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 113100/114400 | Batch Size: 13 | Gen Rate: 18.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 103 (7/7) | Loss: 3.5075 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 104 (7/7) | Loss: 3.4662 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 105 (7/7) | Loss: 3.4826 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 106 (7/7) | Loss: 3.4467 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 107 (7/7) | Loss: 3.5546 | 1.3 steps/s | Step: 1170k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 108 (7/7) | Loss: 3.5370 | 1.2 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 109 (7/7) | Loss: 3.4710 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 110 (7/7) | Loss: 3.5233 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 111 (7/7) | Loss: 3.4802 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 112 (7/7) | Loss: 3.4727 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 113 (7/7) | Loss: 3.4987 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 114 (7/7) | Loss: 3.4677 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 115 (7/7) | Loss: 3.4848 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 116 (7/7) | Loss: 3.4904 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 78300/79200 | Batch Size: 9 | Gen Rate: 13.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 117 (7/7) | Loss: 3.4440 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 118 (7/7) | Loss: 3.4477 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 119 (7/7) | Loss: 3.4823 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 95700/96800 | Batch Size: 11 | Gen Rate: 16.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 120 (7/7) | Loss: 3.4790 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 121 (7/7) | Loss: 3.5219 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 122 (7/7) | Loss: 3.3963 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 123 (7/7) | Loss: 3.5026 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 124 (7/7) | Loss: 3.4668 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 125 (7/7) | Loss: 3.4668 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 126 (7/7) | Loss: 3.4494 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 5.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 127 (7/7) | Loss: 3.4541 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 128 (7/7) | Loss: 3.4266 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 78300/79200 | Batch Size: 9 | Gen Rate: 13.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 129 (7/7) | Loss: 3.4761 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 130 (7/7) | Loss: 3.4998 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 131 (7/7) | Loss: 3.4541 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 132 (7/7) | Loss: 3.5056 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 133 (7/7) | Loss: 3.4810 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 134 (7/7) | Loss: 3.4669 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 135 (7/7) | Loss: 3.4618 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 136 (7/7) | Loss: 3.4432 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 137 (7/7) | Loss: 3.4730 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 138 (7/7) | Loss: 3.4836 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 139 (7/7) | Loss: 3.4887 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 140 (7/7) | Loss: 3.4676 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 141 (7/7) | Loss: 3.5092 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 142 (7/7) | Loss: 3.5050 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 143 (7/7) | Loss: 3.4858 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 144 (7/7) | Loss: 3.5194 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 145 (7/7) | Loss: 3.4374 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 146 (7/7) | Loss: 3.4611 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 147 (7/7) | Loss: 3.5241 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 148 (7/7) | Loss: 3.4757 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 149 (7/7) | Loss: 3.4490 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 150 (7/7) | Loss: 3.4667 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 151 (7/7) | Loss: 3.4769 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 152 (7/7) | Loss: 3.4823 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 153 (7/7) | Loss: 3.4812 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 154 (7/7) | Loss: 3.4570 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 155 (7/7) | Loss: 3.4317 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 156 (7/7) | Loss: 3.5049 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 157 (7/7) | Loss: 3.4536 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 158 (7/7) | Loss: 3.4731 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 159 (7/7) | Loss: 3.5098 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 160 (7/7) | Loss: 3.4411 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 161 (7/7) | Loss: 3.4613 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 162 (7/7) | Loss: 3.4536 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 163 (7/7) | Loss: 3.4721 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 164 (7/7) | Loss: 3.5079 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 165 (7/7) | Loss: 3.4550 | 1.2 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 166 (7/7) | Loss: 3.4862 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 167 (7/7) | Loss: 3.4493 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 168 (7/7) | Loss: 3.5231 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 169 (7/7) | Loss: 3.4979 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 170 (7/7) | Loss: 3.4924 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 171 (7/7) | Loss: 3.4424 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 172 (7/7) | Loss: 3.5002 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 173 (7/7) | Loss: 3.4171 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 174 (7/7) | Loss: 3.4231 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 175 (7/7) | Loss: 3.4631 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 176 (7/7) | Loss: 3.5024 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 177 (7/7) | Loss: 3.4677 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 178 (7/7) | Loss: 3.4663 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 87000/88000 | Batch Size: 10 | Gen Rate: 15.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 179 (7/7) | Loss: 3.4559 | 1.1 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 180 (7/7) | Loss: 3.4240 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 181 (7/7) | Loss: 3.4540 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 182 (7/7) | Loss: 3.4895 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 183 (7/7) | Loss: 3.4696 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 184 (7/7) | Loss: 3.4740 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 185 (7/7) | Loss: 3.4803 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 186 (7/7) | Loss: 3.4510 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 187 (7/7) | Loss: 3.4798 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 188 (7/7) | Loss: 3.5443 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 189 (7/7) | Loss: 3.5089 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 190 (7/7) | Loss: 3.4405 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 8.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 191 (7/7) | Loss: 3.4820 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 95700/96800 | Batch Size: 11 | Gen Rate: 17.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 192 (7/7) | Loss: 3.4823 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 193 (7/7) | Loss: 3.4844 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 8.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 194 (7/7) | Loss: 3.4725 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 195 (7/7) | Loss: 3.4410 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 196 (7/7) | Loss: 3.4636 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 197 (7/7) | Loss: 3.5344 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 198 (7/7) | Loss: 3.5176 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 199 (7/7) | Loss: 3.4889 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 200 (7/7) | Loss: 3.4922 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 201 (7/7) | Loss: 3.5166 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 202 (7/7) | Loss: 3.4728 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 203 (7/7) | Loss: 3.4784 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 204 (7/7) | Loss: 3.4520 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 205 (7/7) | Loss: 3.4679 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 206 (7/7) | Loss: 3.4590 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 207 (7/7) | Loss: 3.4724 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 208 (7/7) | Loss: 3.4971 | 1.2 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 209 (7/7) | Loss: 3.5460 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 95700/96800 | Batch Size: 11 | Gen Rate: 16.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 210 (7/7) | Loss: 3.5367 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 211 (7/7) | Loss: 3.4793 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 212 (7/7) | Loss: 3.5067 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 213 (7/7) | Loss: 3.4822 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 214 (7/7) | Loss: 3.4539 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 215 (7/7) | Loss: 3.4870 | 1.2 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 216 (7/7) | Loss: 3.5245 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 217 (7/7) | Loss: 3.4767 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 218 (7/7) | Loss: 3.4984 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 219 (7/7) | Loss: 3.5307 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 220 (7/7) | Loss: 3.4253 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 221 (7/7) | Loss: 3.4827 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 222 (7/7) | Loss: 3.4433 | 1.2 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 223 (7/7) | Loss: 3.4960 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 224 (7/7) | Loss: 3.4865 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 225 (7/7) | Loss: 3.4830 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 87000/88000 | Batch Size: 10 | Gen Rate: 15.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 226 (7/7) | Loss: 3.5090 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 227 (7/7) | Loss: 3.4985 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 228 (7/7) | Loss: 3.4884 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 229 (7/7) | Loss: 3.4814 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 230 (7/7) | Loss: 3.4216 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 231 (7/7) | Loss: 3.4666 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 78300/79200 | Batch Size: 9 | Gen Rate: 13.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 232 (7/7) | Loss: 3.4644 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 233 (7/7) | Loss: 3.4476 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 78300/79200 | Batch Size: 9 | Gen Rate: 13.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 234 (7/7) | Loss: 3.4966 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 235 (7/7) | Loss: 3.4696 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 236 (7/7) | Loss: 3.4348 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 237 (7/7) | Loss: 3.4577 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 238 (7/7) | Loss: 3.4620 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 239 (7/7) | Loss: 3.4750 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 240 (7/7) | Loss: 3.4959 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 241 (7/7) | Loss: 3.5348 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 242 (7/7) | Loss: 3.4684 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 243 (7/7) | Loss: 3.4500 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 244 (7/7) | Loss: 3.4646 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 245 (7/7) | Loss: 3.4745 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 246 (7/7) | Loss: 3.4708 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 247 (7/7) | Loss: 3.5001 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 248 (7/7) | Loss: 3.4847 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 249 (7/7) | Loss: 3.4928 | 1.3 steps/s | Step: 1171k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 250 (7/7) | Loss: 3.4401 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 251 (7/7) | Loss: 3.4832 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 252 (7/7) | Loss: 3.4727 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 253 (7/7) | Loss: 3.5246 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 254 (7/7) | Loss: 3.4897 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 255 (7/7) | Loss: 3.5433 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 256 (7/7) | Loss: 3.4886 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 257 (7/7) | Loss: 3.4930 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 258 (7/7) | Loss: 3.4592 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 259 (7/7) | Loss: 3.4967 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 260 (7/7) | Loss: 3.4361 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 261 (7/7) | Loss: 3.4769 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 262 (7/7) | Loss: 3.4753 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 263 (7/7) | Loss: 3.4647 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 264 (7/7) | Loss: 3.4816 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 265 (7/7) | Loss: 3.5092 | 1.2 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 266 (7/7) | Loss: 3.4782 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 267 (7/7) | Loss: 3.4626 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 268 (7/7) | Loss: 3.4723 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 269 (7/7) | Loss: 3.5066 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 270 (7/7) | Loss: 3.4824 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 271 (7/7) | Loss: 3.5133 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 272 (7/7) | Loss: 3.4679 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 273 (7/7) | Loss: 3.4791 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 274 (7/7) | Loss: 3.4799 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 78300/79200 | Batch Size: 9 | Gen Rate: 13.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 275 (7/7) | Loss: 3.4742 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 276 (7/7) | Loss: 3.4849 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 277 (7/7) | Loss: 3.5353 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 278 (7/7) | Loss: 3.4987 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 279 (7/7) | Loss: 3.4805 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 5.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 280 (7/7) | Loss: 3.4601 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 281 (7/7) | Loss: 3.4836 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 8.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 282 (7/7) | Loss: 3.4899 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 283 (7/7) | Loss: 3.4542 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 284 (7/7) | Loss: 3.5235 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 11.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 285 (7/7) | Loss: 3.4975 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 286 (7/7) | Loss: 3.4548 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 11.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 287 (7/7) | Loss: 3.4664 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 288 (7/7) | Loss: 3.5086 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 289 (7/7) | Loss: 3.4778 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 290 (7/7) | Loss: 3.4621 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 291 (7/7) | Loss: 3.5070 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 292 (7/7) | Loss: 3.4906 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 293 (7/7) | Loss: 3.4669 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 5.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 294 (7/7) | Loss: 3.4781 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 295 (7/7) | Loss: 3.4951 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 296 (7/7) | Loss: 3.4427 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 297 (7/7) | Loss: 3.4669 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 8.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 298 (7/7) | Loss: 3.5024 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 8.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 299 (7/7) | Loss: 3.4738 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 300 (7/7) | Loss: 3.4624 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 301 (7/7) | Loss: 3.4616 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 302 (7/7) | Loss: 3.4709 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 303 (7/7) | Loss: 3.4686 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 104400/105600 | Batch Size: 12 | Gen Rate: 17.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 304 (7/7) | Loss: 3.5023 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 305 (7/7) | Loss: 3.4898 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 8.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 306 (7/7) | Loss: 3.4530 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 307 (7/7) | Loss: 3.4670 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 308 (7/7) | Loss: 3.5136 | 1.2 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 309 (7/7) | Loss: 3.4720 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 310 (7/7) | Loss: 3.4942 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 311 (7/7) | Loss: 3.4369 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 312 (7/7) | Loss: 3.5195 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 313 (7/7) | Loss: 3.4521 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 314 (7/7) | Loss: 3.4891 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 315 (7/7) | Loss: 3.4746 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 316 (7/7) | Loss: 3.4982 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 317 (7/7) | Loss: 3.4787 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 318 (7/7) | Loss: 3.4811 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 319 (7/7) | Loss: 3.4682 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 320 (7/7) | Loss: 3.5063 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 321 (7/7) | Loss: 3.5510 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 8.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 322 (7/7) | Loss: 3.5095 | 1.2 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 8.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 323 (7/7) | Loss: 3.4835 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.2kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 324 (7/7) | Loss: 3.4487 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 8.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 325 (7/7) | Loss: 3.4713 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 326 (7/7) | Loss: 3.4644 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 327 (7/7) | Loss: 3.4700 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 11.9kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 328 (7/7) | Loss: 3.4643 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 329 (7/7) | Loss: 3.4822 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 330 (7/7) | Loss: 3.4599 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 11.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 331 (7/7) | Loss: 3.5017 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 11.8kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 332 (7/7) | Loss: 3.4726 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 333 (7/7) | Loss: 3.4816 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 334 (7/7) | Loss: 3.4775 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.4kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 335 (7/7) | Loss: 3.4873 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 336 (7/7) | Loss: 3.4875 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 11.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 337 (7/7) | Loss: 3.4869 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 60900/61600 | Batch Size: 7 | Gen Rate: 10.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 338 (7/7) | Loss: 3.4957 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 339 (7/7) | Loss: 3.5000 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 340 (7/7) | Loss: 3.5220 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 341 (7/7) | Loss: 3.4897 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 69600/70400 | Batch Size: 8 | Gen Rate: 12.3kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 342 (7/7) | Loss: 3.4372 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 343 (7/7) | Loss: 3.4712 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 43500/44000 | Batch Size: 5 | Gen Rate: 7.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 344 (7/7) | Loss: 3.5013 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 78300/79200 | Batch Size: 9 | Gen Rate: 13.6kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 345 (7/7) | Loss: 3.4362 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 34800/35200 | Batch Size: 4 | Gen Rate: 6.1kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 346 (7/7) | Loss: 3.4627 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.7kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 347 (7/7) | Loss: 3.4508 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 26100/26400 | Batch Size: 3 | Gen Rate: 4.5kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 348 (7/7) | Loss: 3.4537 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 95700/96800 | Batch Size: 11 | Gen Rate: 16.0kHz | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 349 (7/7) | Loss: 3.4502 | 1.3 steps/s | Step: 1172k | }\n",
            "| Generating: 1/1\n",
            "{| ████████████████ 52200/52800 | Batch Size: 6 | Gen Rate: 9.2kHz | }\n"
          ]
        }
      ],
      "source": [
        "!python vocoder_train.py pretrained synthesizer/saved_models/logs-singlespeaker/datasets_root --save_every 100 --backup_every 250"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEX3uvksQQnl"
      },
      "source": [
        "and building a framework that the business can use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPmg7MX9ghZB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FclZFjRKcVZ"
      },
      "source": [
        "#IGNORE ALL OF THESE CELLS BELOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YPhVzFKnktI",
        "outputId": "8ef3f527-09f4-4945-c86e-8ec8b42462b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    datasets_root:   /content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root\n",
            "    out_dir:         /content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer\n",
            "    n_processes:     None\n",
            "    skip_existing:   False\n",
            "    hparams:         \n",
            "    no_alignments:   True\n",
            "    datasets_name:   LibriSpeech\n",
            "    subfolders:      train-clean-100\n",
            "\n",
            "Using data from:\n",
            "    /content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/LibriSpeech/train-clean-100\n",
            "=====Speaker directory========\n",
            "[PosixPath('/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/LibriSpeech/train-clean-100/211'), PosixPath('/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root/LibriSpeech/train-clean-100/SV2TTS')]\n",
            "LibriSpeech:   0% 0/2 [00:00<?, ?speakers/s]\n",
            "multiprocessing.pool.RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/preprocess.py\", line 78, in preprocess_speaker\n",
            "    assert text_fpath.exists()\n",
            "AssertionError\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"synthesizer_preprocess_audio.py\", line 59, in <module>\n",
            "    preprocess_dataset(**vars(args))\n",
            "  File \"/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/preprocess.py\", line 37, in preprocess_dataset\n",
            "    for speaker_metadata in tqdm(job, datasets_name, len(speaker_dirs), unit=\"speakers\"):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1180, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 748, in next\n",
            "    raise value\n",
            "AssertionError\n"
          ]
        }
      ],
      "source": [
        "!python synthesizer_preprocess_audio.py --no_alignments '/content/drive/MyDrive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-singlespeaker/datasets_root' --datasets_name 'LibriSpeech' --subfolders 'train-clean-100' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDJjJ44IE6lo",
        "outputId": "cde93541-3a95-4a63-ee38-bdd4881364f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    datasets_root:   /content/drive/MyDrive/Voice Cloning/Text-toSpeech/DrBayoaudio_and_transcript\n",
            "    out_dir:         /content/drive/MyDrive/Voice Cloning/Text-toSpeech/DrBayoaudio_and_transcript/SV2TTS/synthesizer\n",
            "    n_processes:     None\n",
            "    skip_existing:   False\n",
            "    hparams:         \n",
            "    no_alignments:   False\n",
            "    datasets_name:   audiosNtranscripts\n",
            "    subfolders:      speakers\n",
            "\n",
            "Using data from:\n",
            "    /content/drive/MyDrive/Voice Cloning/Text-toSpeech/DrBayoaudio_and_transcript/audiosNtranscripts/speakers\n",
            "=====Speaker directory========\n",
            "[PosixPath('/content/drive/MyDrive/Voice Cloning/Text-toSpeech/DrBayoaudio_and_transcript/audiosNtranscripts/speakers/.ipynb_checkpoints'), PosixPath('/content/drive/MyDrive/Voice Cloning/Text-toSpeech/DrBayoaudio_and_transcript/audiosNtranscripts/speakers/Dr_Bayo')]\n",
            "audiosNtranscripts: 100% 2/2 [00:00<00:00, 180.06speakers/s]\n",
            "The dataset consists of 0 utterances, 0 mel frames, 0 audio timesteps (0.00 hours).\n",
            "Traceback (most recent call last):\n",
            "  File \"synthesizer_preprocess_audio.py\", line 59, in <module>\n",
            "    preprocess_dataset(**vars(args))\n",
            "  File \"/content/drive/My Drive/Voice Cloning/Real-Time-Voice-Cloning/synthesizer/preprocess.py\", line 51, in preprocess_dataset\n",
            "    print(\"Max input length (text chars): %d\" % max(len(m[5]) for m in metadata))\n",
            "ValueError: max() arg is an empty sequence\n"
          ]
        }
      ],
      "source": [
        "y!python synthesizer_preprocess_audio.py '/content/drive/MyDrive/Voice Cloning/Text-toSpeech/DrBayoaudio_and_transcript' --datasets_name 'audiosNtranscripts' --subfolders 'speakers' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgPoruJEzxne",
        "outputId": "e48ba175-e7db-496e-cf52-7277ace9ff48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arguments:\n",
            "    run_id:          pretrained\n",
            "    syn_dir:         synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer\n",
            "    models_dir:      synthesizer/saved_models/\n",
            "    save_every:      125\n",
            "    backup_every:    100\n",
            "    force_restart:   False\n",
            "    hparams:         \n",
            "\n",
            "Checkpoint path: synthesizer/saved_models/pretrained/pretrained.pt\n",
            "Loading training data from: synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/train.txt\n",
            "Using model: Tacotron\n",
            "Using device: cuda\n",
            "\n",
            "Initialising Tacotron Model...\n",
            "\n",
            "Trainable Parameters: 30.870M\n",
            "\n",
            "Starting the training of Tacotron from scratch\n",
            "\n",
            "Using inputs from:\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/train.txt\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/mels\n",
            "\tsynthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer/embeds\n",
            "Found 143 samples\n",
            "+----------------+------------+---------------+------------------+\n",
            "| Steps with r=2 | Batch Size | Learning Rate | Outputs/Step (r) |\n",
            "+----------------+------------+---------------+------------------+\n",
            "|   20k Steps    |     12     |     0.001     |        2         |\n",
            "+----------------+------------+---------------+------------------+\n",
            " \n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "{| Epoch: 1/1667 (12/12) | Loss: 7.770 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 2/1667 (12/12) | Loss: 5.025 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 3/1667 (12/12) | Loss: 3.948 | 0.22 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 4/1667 (12/12) | Loss: 3.361 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 5/1667 (12/12) | Loss: 2.971 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 6/1667 (12/12) | Loss: 2.695 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 7/1667 (12/12) | Loss: 2.494 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 8/1667 (12/12) | Loss: 2.335 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 9/1667 (12/12) | Loss: 1.585 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 10/1667 (12/12) | Loss: 1.387 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 11/1667 (12/12) | Loss: 1.286 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 12/1667 (12/12) | Loss: 1.213 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 13/1667 (12/12) | Loss: 1.149 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 14/1667 (12/12) | Loss: 1.098 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 15/1667 (12/12) | Loss: 1.058 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 16/1667 (12/12) | Loss: 1.015 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 17/1667 (12/12) | Loss: 0.9838 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 18/1667 (12/12) | Loss: 0.9551 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 19/1667 (12/12) | Loss: 0.9310 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 20/1667 (12/12) | Loss: 0.9163 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 21/1667 (12/12) | Loss: 0.9034 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 22/1667 (12/12) | Loss: 0.8933 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 23/1667 (12/12) | Loss: 0.8798 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 24/1667 (12/12) | Loss: 0.8665 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 25/1667 (12/12) | Loss: 0.8555 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 26/1667 (12/12) | Loss: 0.8397 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 27/1667 (12/12) | Loss: 0.8328 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 28/1667 (12/12) | Loss: 0.8193 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 29/1667 (12/12) | Loss: 0.8034 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 30/1667 (12/12) | Loss: 0.8010 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 31/1667 (12/12) | Loss: 0.7951 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 32/1667 (12/12) | Loss: 0.7894 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 33/1667 (12/12) | Loss: 0.7863 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 34/1667 (12/12) | Loss: 0.7803 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 35/1667 (12/12) | Loss: 0.7714 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 36/1667 (12/12) | Loss: 0.7726 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 37/1667 (12/12) | Loss: 0.7642 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 38/1667 (12/12) | Loss: 0.7567 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 39/1667 (12/12) | Loss: 0.7461 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 40/1667 (12/12) | Loss: 0.7461 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 41/1667 (12/12) | Loss: 0.7392 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 42/1667 (8/12) | Loss: 0.7311 | 0.23 steps/s | Step: 0k | }Input at step 500: the party was to take place at saint germain i believe and they had appointed to meet at the carmes deschaux when they were disturbed by de jussac cahusac~___________\n",
            "{| Epoch: 42/1667 (12/12) | Loss: 0.7295 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 43/1667 (12/12) | Loss: 0.7241 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 44/1667 (12/12) | Loss: 0.7174 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 45/1667 (12/12) | Loss: 0.7057 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 46/1667 (12/12) | Loss: 0.7003 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 47/1667 (12/12) | Loss: 0.6947 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 48/1667 (12/12) | Loss: 0.6882 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 49/1667 (12/12) | Loss: 0.6837 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 50/1667 (12/12) | Loss: 0.6803 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 51/1667 (12/12) | Loss: 0.6760 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 52/1667 (12/12) | Loss: 0.6743 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 53/1667 (12/12) | Loss: 0.6704 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 54/1667 (12/12) | Loss: 0.6622 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 55/1667 (12/12) | Loss: 0.6587 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 56/1667 (12/12) | Loss: 0.6537 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 57/1667 (12/12) | Loss: 0.6462 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 58/1667 (12/12) | Loss: 0.6420 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 59/1667 (12/12) | Loss: 0.6347 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 60/1667 (12/12) | Loss: 0.6287 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 61/1667 (12/12) | Loss: 0.6232 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 62/1667 (12/12) | Loss: 0.6194 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 63/1667 (12/12) | Loss: 0.6192 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 64/1667 (12/12) | Loss: 0.6145 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 65/1667 (12/12) | Loss: 0.6093 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 66/1667 (12/12) | Loss: 0.6052 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 67/1667 (12/12) | Loss: 0.5986 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 68/1667 (12/12) | Loss: 0.5956 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 69/1667 (12/12) | Loss: 0.5892 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 70/1667 (12/12) | Loss: 0.5814 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 71/1667 (12/12) | Loss: 0.5742 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 72/1667 (12/12) | Loss: 0.5606 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 73/1667 (12/12) | Loss: 0.5532 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 74/1667 (12/12) | Loss: 0.5506 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 75/1667 (12/12) | Loss: 0.5415 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 76/1667 (12/12) | Loss: 0.5399 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 77/1667 (12/12) | Loss: 0.5375 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 78/1667 (12/12) | Loss: 0.5323 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 79/1667 (12/12) | Loss: 0.5294 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 80/1667 (12/12) | Loss: 0.5286 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 81/1667 (12/12) | Loss: 0.5228 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 82/1667 (12/12) | Loss: 0.5185 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 83/1667 (12/12) | Loss: 0.5121 | 0.23 steps/s | Step: 0k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 84/1667 (4/12) | Loss: 0.5094 | 0.23 steps/s | Step: 1k | }Input at step 1000: ah ah you incline me to think so said the king~___________________________________________________________________________________________________\n",
            "{| Epoch: 84/1667 (12/12) | Loss: 0.5052 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 85/1667 (12/12) | Loss: 0.4999 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 86/1667 (12/12) | Loss: 0.4933 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 87/1667 (12/12) | Loss: 0.4886 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 88/1667 (12/12) | Loss: 0.4832 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 89/1667 (12/12) | Loss: 0.4773 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 90/1667 (12/12) | Loss: 0.4690 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 91/1667 (12/12) | Loss: 0.4651 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 92/1667 (12/12) | Loss: 0.4586 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 93/1667 (12/12) | Loss: 0.4542 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 94/1667 (12/12) | Loss: 0.4480 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 95/1667 (12/12) | Loss: 0.4440 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 96/1667 (12/12) | Loss: 0.4432 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 97/1667 (12/12) | Loss: 0.4409 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 98/1667 (12/12) | Loss: 0.4410 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 99/1667 (12/12) | Loss: 0.4366 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 100/1667 (12/12) | Loss: 0.4317 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 101/1667 (12/12) | Loss: 0.4254 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 102/1667 (12/12) | Loss: 0.4220 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 103/1667 (12/12) | Loss: 0.4200 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 104/1667 (12/12) | Loss: 0.4133 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 105/1667 (12/12) | Loss: 0.4092 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 106/1667 (12/12) | Loss: 0.4021 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 107/1667 (12/12) | Loss: 0.3986 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 108/1667 (12/12) | Loss: 0.3963 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 109/1667 (12/12) | Loss: 0.3919 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 110/1667 (12/12) | Loss: 0.3906 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 111/1667 (12/12) | Loss: 0.3872 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 112/1667 (12/12) | Loss: 0.3832 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 113/1667 (12/12) | Loss: 0.3814 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 114/1667 (12/12) | Loss: 0.3781 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 115/1667 (12/12) | Loss: 0.3772 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 116/1667 (12/12) | Loss: 0.3753 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 117/1667 (12/12) | Loss: 0.3733 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 118/1667 (12/12) | Loss: 0.3696 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 119/1667 (12/12) | Loss: 0.3637 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 120/1667 (12/12) | Loss: 0.3625 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 121/1667 (12/12) | Loss: 0.3605 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 122/1667 (12/12) | Loss: 0.3545 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 123/1667 (12/12) | Loss: 0.3513 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 124/1667 (12/12) | Loss: 0.3497 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 125/1667 (12/12) | Loss: 0.3457 | 0.23 steps/s | Step: 1k | }Input at step 1500: the doors of which they closed just in time to prevent their enemies from entering with them~_______________________________________________________________________________________\n",
            "\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 126/1667 (12/12) | Loss: 0.3461 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 127/1667 (12/12) | Loss: 0.3439 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 128/1667 (12/12) | Loss: 0.3412 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 129/1667 (12/12) | Loss: 0.3397 | 0.23 steps/s | Step: 1k | }\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "{| Epoch: 130/1667 (9/12) | Loss: 0.3375 | 0.23 steps/s | Step: 1k | }"
          ]
        }
      ],
      "source": [
        "!python synthesizer_train.py pretrained synthesizer/saved_models/logs-singlespeaker/datasets_root/SV2TTS/synthesizer -s 125 -b 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo"
      ],
      "metadata": {
        "id": "sB-u7D7Ahx7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "JlhNr66Pk22-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "NEYejWUhlPL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hello_world(name):\n",
        "  return \"Hello...\"+ name +\"!!!!!\"\n"
      ],
      "metadata": {
        "id": "vhOsN-l8lUJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hello_world(\"littlecoder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4ybTFWhQnAby",
        "outputId": "3011e92e-a6ea-4ec1-a42f-91ac001cc4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello...littlecoder!!!!!'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(fn = hello_world, inputs = \"text\", outputs = \"audio\")"
      ],
      "metadata": {
        "id": "FCTlrNWcnT-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "ugf8Kmhcn7T4",
        "outputId": "2f9c8aa8-b93e-4652-d2dd-839f3ea74bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://49964.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://49964.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f2132a37490>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<fastapi.applications.FastAPI at 0x7f21405b9750>,\n",
              " 'http://127.0.0.1:7862/',\n",
              " 'https://49964.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overview**\n",
        "\n",
        "Text-->Model(choose Male OR Female) --> Speech"
      ],
      "metadata": {
        "id": "bB5c2DuRAljw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51Dsunhp5yYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "fe65d292-d18c-4499-db34-5a4c40331d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTANT: You are using gradio version 2.3.0a0, however version 2.5.1 is available, please upgrade.\n",
            "--------\n",
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n",
            "Running on public URL: https://10018.gradio.app\n",
            "Interface loading below...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://10018.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fd477de3ad0>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://10018.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "os.system('pip install gradio==2.3.0a0')\n",
        "os.system('pip freeze')\n",
        "import gradio as gr\n",
        "from subprocess import call\n",
        "\n",
        "def run_cmd(command):\n",
        "    try:\n",
        "        print(command)\n",
        "        call(command)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Process interrupted\")\n",
        "        sys.exit(1)\n",
        "\n",
        "def inference(text):\n",
        "  cmd = ['tts', '--text', text]\n",
        "  run_cmd(cmd)\n",
        "  return 'tts_output.wav'\n",
        "  \n",
        "inputs = gr.inputs.Textbox(lines=5, label=\"Input Text\")\n",
        "outputs =  gr.outputs.Audio(type=\"file\",label=\"Output Audio\")\n",
        "title = \"Voice cloning-TTS\"\n",
        "description = \"Gradio demo for coqui-ai-TTS: a deep learning toolkit for Text-to-Speech, battle-tested in research and production. To use it, simply add your text, or click one of the examples to load them. Read more at the links below.\"\n",
        "article = \"<p style='text-align: center'><a href='https://tts.readthedocs.io/en/latest/'>TTS is a library for advanced Text-to-Speech generation</a> | <a href='https://github.com/coqui-ai/TTS'>Github Repo</a></p>\"\n",
        "examples = [\n",
        " [\"This is an open-source library that generates synthetic speech!\"]\n",
        "]\n",
        "gr.Interface(inference, inputs, outputs, title=title, description=description, article=article, examples=examples, enable_queue=True ).launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8FXzv64khn45"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_iJP4hditnba",
        "zXe-moa_ZNb2",
        "CSK0wwpVblJT"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}